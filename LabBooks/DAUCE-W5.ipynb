{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-01-03 - linear regression\n",
    "---\n",
    "Pas de Notebook pour la 4e semaine de stage, qui correspond à la pause hivernale.  \n",
    "Le semaine 5 est courte, le labo étant fermé lundi (ferié) et mardi.  \n",
    "L'absence pendant une semaine + la semaine courte me met encore plus en retard que je ne l'étais déjà.  \n",
    "\n",
    "Pour répondre à la thématique du stage (modélisation du comportement de la voie magnocellulaire), je pense qu'il faut que j'ai dans ma biblio au moins une review décrivant ce comportement.  \n",
    "\n",
    "J'ai trouvé quelques articles intéressants, que je place dans la section \"A lire\".  \n",
    "\n",
    "Le script *Waveimage tensorflow-pow3-encoding* que m'a envoyé Daucé utilise un kernel Python2, mais j'utilise habituellement un kernel Python3, ce qui fait qu'il me manque un certain nombre de dépendances pour le lancer. Je le traduit pas à pas en Python3 pour pouvoir le lancer et l'utiliser parce qu'il ne semble pas possible de modifier le kernel d'un script après sa création sous Jupyter.  \n",
    "\n",
    "Le script *Waveimage-tensorflow-pow3-encoding_P3ver* permet donc d'obtenir un échantillon d'images provenant de MNIST, de modifier la taille et l'emplacement du stimulus dans l'image et de simuler une vue fovéale via une dégradation de la qualité de l'image avec la distance du point central (via l'application de wavelets).  \n",
    "Il faut maintenant que j'écrive un script pouvant détecter la position de la cible, en premier lieu via une régression linéaire ([linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) ?) pour ensuite imposer une action entrainant le mouvement du centre de fixation vers le lieu prédit de la cible.  \n",
    "\n",
    "Essai d'algorythmique pour m'aider à avancer : \n",
    "\n",
    "    RECOIT valeurs vecteurs pow3_one_hot d'une image (X) OU valeurs individuelles des pixels (X)\n",
    "    CALCULE région de plus grande valeur :\n",
    "        SI valeur pixel n > valeur autres pixels\n",
    "        ALORS coordonnées pixel n == coordonnées d'intérêt\n",
    "    TANT QUE coordonnées d'intéret != coordonnées point de fixation :\n",
    "        ALORS coordonnées point de fixation (y) == coordonnées d'intérêt\n",
    "        \n",
    "Le codage one-hot me semble présenter une limite : dans une perception bruitée ou écologique, ce codage ne représentera pas forcément la localisation d'un stimulus d'intéret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-01-04 - linear regression\n",
    "---\n",
    "\n",
    "Le modèle comprends\n",
    "+ Entrée : vector data, provenant de la fonction \"generate_vector_data_with_offset_from_x\"\n",
    "+ Hypothèse : position de la cible\n",
    "+ Sortie : coordonnées de la cible  \n",
    "\n",
    "Lors du calcul de l'hypothèse, j'ai donc deux *x* correspondant aux coordonnées x et y.\n",
    "\n",
    "Je travaille actuellement sur le script *Waveimage-tensorflow-pow3-encoding_P3ver*. Les avancées y sont notées.  \n",
    "\n",
    "Denison2014 cite des études explorant la possibilité que le LGN humain supporte des aspects haut-niveau de la vision (Kastner, 2016) et d'autres explorant la contribution des sous-divisions M et P dans l'attention spatiale (Cheng2004, Theeuwes1995, Yeshurun2003;2004;2012) et la sélection perceptuelle (Denison2012). Il serait intéressant d'y jeter un oeil plus tard dans le projet.  \n",
    "\n",
    "L'efficacité du script que j'écris pourra être confrontée à celle d'un script [scikit-learn](https://github.com/scikit-learn/scikit-learn).  \n",
    "\n",
    "Je bloque sur un passage. Lors du calcul du cout, je dois soustraire l'output *y* à l'hypothèse *h0(X)*.  \n",
    "L'output *y* correspond à la position de la cible et comprends les coordonnées *i* (ou *y0*) et *j* (ou *y1*).  \n",
    "J'ai calculé l'hypothèse *h0(X)* sous forme \n",
    "\n",
    "    h0(X) = Theta0*x0 + Theta1*x1 + Theta2*x2 + ... + Thetan*xn\n",
    "    \n",
    "Comment est-ce que je peux comparer l'output qui à deux valeurs à l'hypothèse qui est un vecteur à n valeurs?  \n",
    "L'hypothèse n'est-elle pas censé comprendre aussi deux valeurs, représentant les coordonnées prédites de la cible? Du coup comment est-ce que je peux retrouver des coordonnées à partir de ce vecteur?  \n",
    "\n",
    "Daucé m'a dit qu'il me faudrait deux séries de paramètres, une pour estimer la coordonnée *y0* et l'autre *y1*. Il faudrait donc que j'applique indépendamment ces séries, et j'aurai deux hypothèses (une hypothèse pour chaque coordonnée), deux coûts et je vais devoir réaliser deux fois le gradient descent. Si j'ai compris (ce qui n'est pas encore sur).  \n",
    "Reste le problème de comparer un vecteur à une valeur (*y0* puis *y1*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-01-05 - linear regression\n",
    "---\n",
    "Pour comparer *hO(x)* avec *y*, le premier doit n'être qu'une seule valeur. Pour ça je dois réaliser le produit scalaire de tous les *theta_n x x_n*, comme l'indique sa formule...  \n",
    "J'ai réussi à obtenir une valeur unique pour la square error, mais le code n'est pas du tout optimisé, il faudra que j'y revienne pour le nettoyer/vérifier s'il est juste.  \n",
    "\n",
    "Après une journée de travail et l'aide de Daucé, le script de multivariate linear regression est maintenant fonctionnel. Il faut maintenant que j'en fasse une fonction permettant de réaliser une itération, puis que j'intègre le choix du nombre d'itérations.  \n",
    "\n",
    "La dernière grosse étape consistera au calcul du cout, pour observer si l'apprentissage se fait correctement au fil des itérations et réaliser un benchmarking sur l'effet d'alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# To Do\n",
    "+ Se renseigner sur Mendeley pour gérer la biblio, la partager en ligne avec Daucé et Perrinet\n",
    "+ S'inscrire sur la liste de diffusion privée de l'INS\n",
    "+ ~~Trouver une review complète sur le comportement de la voie magnocellulaire~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A lire\n",
    "+ http://bethgelab.org/media/publications/Kuemmerer_High_Low_Level_Fixations_ICCV_2017.pdf\n",
    "+ https://pdfs.semanticscholar.org/0182/5573781674bcf85d0f5d2ec456842f75ad3c.pdf\n",
    "+ Schmidhuber, 1991 (voir mail Daucé)\n",
    "+ Parr and Friston, 2017 (voir mail Perrinet)\n",
    "+ http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003005#s1  \n",
    "### Magnocellular pathway function  \n",
    "+ [Selective suppression of the magnocellular visual pathway during saccadic eye movements](http://www.nature.com.lama.univ-amu.fr/articles/371511a0), Burr1994\n",
    "+ ~~[Functional mapping of the magnocellular and parvocellular subdivisions of human LGN](http://www.sciencedirect.com.lama.univ-amu.fr/science/article/pii/S1053811914005916?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&ccp=y), Denison2014~~\n",
    "+ [On Identifying Magnocellular and Parvocellular Responses on the Basis of Contrast-Response Functions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3004196/), Skottun2011\n",
    "+ [Review: Steady and pulsed pedestals, the how and why of post-receptoral pathway separation](http://jov.arvojournals.org/article.aspx?articleid=2191890), Pokorny2011\n",
    "+ [An evolving view of duplex vision: separate but interacting cortical pathways for perception and action](http://www.sciencedirect.com/science/article/pii/S0959438804000340?via%3Dihub), Goodale2004"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
