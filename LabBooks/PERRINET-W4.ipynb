{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-04-03\n",
    "---\n",
    "L'évaluation de la partie What du modèle retourne une performance bien trop faible, en dessous même du hasard (10%):\n",
    "\n",
    "    Test set: Average loss: 2.3068, Accuracy: 10/10000 (0%), Elapsed time (%mn): 1.480791\n",
    "    \n",
    "Mais lorsque j'imprime la variable \"correct\":\n",
    "\n",
    "    (...)\n",
    "    4\n",
    "    9\n",
    "    5\n",
    "    10\n",
    "    7\n",
    "    4\n",
    "    11\n",
    "    12\n",
    "    (...)\n",
    "    \n",
    "Après avoir changé l'évaluation du nombre de prédictions correctes de:\n",
    "\n",
    "        correct = pred.eq(LABEL.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "Vers: \n",
    "\n",
    "        correct += pred.eq(LABEL.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "J'obtient toujours une performance très faible mais proche des 10% du hasard:\n",
    "\n",
    "    Test set: Average loss: 2.3068, Accuracy: 892/10000 (9%), Elapsed time (%mn): 1.486337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-04-04\n",
    "---\n",
    "Confusion matrix souvent utilisées pour réaliser un benchmarking de classifieurs (montre quelles classes sont les plus difficiles à discriminer).  \n",
    "Pour obtenir les poids entrainés:\n",
    "\n",
    "    model.parameters()\n",
    "    \n",
    "Pour les imprimer:\n",
    "\n",
    "    print(list(model.parameters()))\n",
    "    \n",
    "Ce [lien](https://stackoverflow.com/questions/48477198/problems-with-pytorch-mlp-when-training-the-mnist-dataset-retrieved-from-keras) explique la performance nulle (10% même au centre) par l'absence de normalisation des données. Celles-ci le sont lorsqu'elles sont chargées en début de script mais pas après transformation vers du 128x128.\n",
    "\n",
    "La performance est toujours minime, même si je réalise l'entrainement au centre de l'image :\n",
    "\n",
    "    Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.296373\tElapsed time: 0.00 mn\n",
    "    Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.305507\tElapsed time: 0.03 mn\n",
    "    (...)\n",
    "    Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.298825\tElapsed time: 0.32 mn\n",
    "    Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.300486\tElapsed time: 0.36 mn\n",
    "\n",
    "    Test set: Average loss: 2.3024, Accuracy: 982/10000 (10%), Elapsed time: 0.03 mn\n",
    "    \n",
    "Le problème étant que j'ai besoin d'obtenir une bonne performance au moins dans le centre de l'image pour construire la carte de certitude qui doit être intégrée dans la base de données que j'essaie de construire.  \n",
    "\n",
    "A force de bidouillages pour essayer d'améliorer ces performances, j'ai tout de même réussi à fortement réduire sa durée (moins d'une minute par epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# To Do\n",
    "+ **Créer la base de données qui servira pour l'apprentissage et l'évaluation**. Cette base devra comprendre pour l'ensemble des situations possibles (coordonnées transformables) les cartes rétinienne (LogPolaire de l'image) et colliculaires (LogPolaire de la carte de certitude) correspondantes\n",
    "+ Transformer les script ipynb de notes en nb\n",
    "### Rapport M2b\n",
    "+ **Ecrire une ébauche d'introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A lire\n",
    "+ http://bethgelab.org/media/publications/Kuemmerer_High_Low_Level_Fixations_ICCV_2017.pdf\n",
    "+ https://pdfs.semanticscholar.org/0182/5573781674bcf85d0f5d2ec456842f75ad3c.pdf\n",
    "+ Schmidhuber, 1991 (voir mail Daucé)\n",
    "+ Parr and Friston, 2017 (voir mail Perrinet)\n",
    "+ http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003005#s1\n",
    "+ http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf\n",
    "+ https://www.nature.com/articles/sdata2016126\n",
    "+ [Liu et al., 2016](http://ieeexplore.ieee.org/document/7762165/?reload=true) : Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks\n",
    "+ [Papier utilisant une méthode similaire à la notre + intégration en robotique](https://www.researchgate.net/publication/220934961_Fast_Object_Detection_with_Foveated_Imaging_and_Virtual_Saccades_on_Resource_Limited_Robots)\n",
    "### Magnocellular pathway function  \n",
    "+ [Selective suppression of the magnocellular visual pathway during saccadic eye movements](http://www.nature.com.lama.univ-amu.fr/articles/371511a0), Burr1994\n",
    "+ [On Identifying Magnocellular and Parvocellular Responses on the Basis of Contrast-Response Functions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3004196/), Skottun2011\n",
    "+ [Review: Steady and pulsed pedestals, the how and why of post-receptoral pathway separation](http://jov.arvojournals.org/article.aspx?articleid=2191890), Pokorny2011\n",
    "+ [An evolving view of duplex vision: separate but interacting cortical pathways for perception and action](http://www.sciencedirect.com/science/article/pii/S0959438804000340?via%3Dihub), Goodale2004\n",
    "+ [Quantitative measurement of saccade amplitude, duration, and velocity](http://n.neurology.org/content/25/11/1065), Baloh1975\n",
    "### Peripherical vision function\n",
    "+ [The Role of Peripheral Vision in Configural Spatial Knowledge Acquisition](https://etd.ohiolink.edu/pg_10?0::NO:10:P10_ACCESSION_NUM:wright1496188017928082), Douglas2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Satellites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
