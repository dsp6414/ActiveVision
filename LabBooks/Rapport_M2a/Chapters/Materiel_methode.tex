% Chapter Template

\chapter{Matériel et méthodes} % Main chapter title
\label{Materiel_methode} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------

\section{Support physique et numérique} %Spécificités ordinateur/machine virtuelle, python/libraries versions
L'ensemble des modélisations ont été réalisés sur un ordinateur portable hébergeant une machine virtuelle. Leurs caractéristiques sont rassemblées dans le tableau~\ref{tab:materiel}.\\
Les modélisation ont été réalisées à l'aide du language de programmation \href{https://www.python.org/}{Python} (version 3.6.4) renforcé de la librairie \href{https://www.tensorflow.org/}{TensorFlow} (version 1.4) et de l'interface graphique \href{https://jupyter.org/}{Jupyter}.\\
La base de données \href{http://yann.lecun.com/exdb/mnist/}{MNIST} a été utilisée pour l'apprentissage et l'évaluation du modèle. Elle contient 70.000 images de chiffres manuscrits (60.000 pour l'entraînement, 10.000 pour l'évaluation), centrés et dont la taille a été normalisée. Chaque image est accompagnée d'un label décrivant quel chiffre elle contient.

%----------------------------------------------------------------------------------------

\section{Modèle POMDP} %Description du modèle perception-action, schéma explicatif
Le problème de recherche d'information dans un contexte d'exploration de l'environnement visuel peut être formulé comme un \textbf{processus de décision Markovien partiellement observable} (POMDP) \autocite{Butko2010}. \\
Dans un POMDP (figure~\ref{fig:POMDP}), l'agent perçoit partiellement l'\textbf{état de l'environnement} \textit{S} à un temps \textit{t} (dans ce travail, l'environnement visuel) et peut réaliser des \textbf{actions} \textit{A} (ici des saccades oculaires) qui peuvent avoir des conséquences sur l'environnement et sa perception \textit{O} (l'environnement visuel perçut au travers du champs rétinien). L'agent va ainsi construire un \textbf{état de croyance} \textit{B} (ici les prédictions de position et de catégorie du stimulus) en fonction des observations et des actions réalisées jusqu'ici \autocite{Butko2010}.

Un tel système doit satisfaire la \textbf{propriété de Markov}, qui décrit que la distribution de probabilité des futurs états ne dépends que de l'état précédent et pas de toute la séquence d'états en amont.\\
Ainsi lors de l'évolution du système dans le temps, on considère que l'état suivant de l'environnement est uniquement influencé par son état actuel et l'action (éventuelle) réalisée par l'agent (équation~\ref{eqn:POMDP_sta}) \autocite{Butko2010}. 

\begin{equation}
p(s_{t+1}|s_{1:t},a_{1:t},o_{1:t}) = p(s_{t+1}|s_{t},a_{t})
\label{eqn:POMDP_sta}
\end{equation}

De même, les observations actuelles de l'agent ne dépendent que de l'état actuel de l'environnement et de l'action (éventuelle) qu'il réalise (équation~\ref{eqn:POMDP_obs}) \autocite{Butko2010}.

\begin{equation}
p(o_{t}|s_{1:t},a_{1:t}) = p(o_{t}|s_{t},a_{t})
\label{eqn:POMDP_obs}
\end{equation}

\begin{equation}
B_{t}^i = p(S_{t} = i|A_{1:t},O_{1:t})
\label{eqn:POMDP_bel}
\end{equation}

Nous construisons ainsi un modèle en deux couches. La première, \textit{détecteur}, est entraînée à prédire la position du stimulus dans l'image perçu au travers du champs rétinien, permettant de réaliser une saccade jusqu'aux coordonnées prédites et donc d'approcher la cible de la vision fovéale. Chaque saccade permet d'optimiser la détection du signal.\autocite{Friston2012}\\
La seconde, \textit{classifieur}, est entraînée à prédire la catégorie du stimulus dans l'image, perçu au travers du champs rétinien et permet d'arrêter l'exploration de l'image lorsque sa prédiction présente une certitude assez élevée.

%----------------------------------------------------------------------------------------

\section{Champs rétinien} %Description du modèle logpolar

Avant d'être utilisée par le modèle, l'image provenant de la base MNIST subit un certain nombre de transformations.\\
Chaque image présente originellement des niveaux de gris sur 28x28 pixels. Cette image est placée au hasard (mais de façon normocentrée) sur une image au fond blanc de 128x128 pixels (figure~\ref{fig:mnist_reshape}).\\
A cette image est ensuite appliqué un \textit{filtre Wavelets} ou un \textit{filtre LogPolar}, deux méthodes permettant d'obtenir un champs rétinien, c'est à dire un filtre visuel dont l'acuité est maximale en son centre (simulant la fovea) et diminuant avec l'excentricité (simulant la vision périphérique). Les produits de ces méthodes et leurs théories sous-jacentes seront décrits dans ce document, mais leurs résultats ne peuvent pas être comparés tels quels, leurs architectures n'étant pas au même niveau d'aboutissement (la couche \textit{classifieur} étant par exemple seulement intégré avec la filtre LogPolar pour le moment).\\
!!! Description filtre wavelets!!! \\
Les effets du \textit{filtre Wavelets} sont visibles sur la figure~\ref{fig:wavelet_effect}.\\
!!! Description filtre LogPolar !!!\\
L'une des forces du filtre LogPolar est sa capacité à modéliser la distribution des champs récepteurs rétinien, mais aussi (en modifiant seulement quelques paramètres) celle d'aires corticales visuelles primaires et associatives et peut donc être ré-utilisé dans le cadre d'un modèle visuel multi-couches neuromimétique, notamment pour la modélisation de la voie visuelle ventrale \autocite{Freeman2011}.

%----------------------------------------------------------------------------------------

\section{Apprentissage supervisé} %Formules du modèle mathématiques soutenant la Régression linéaire multivariée
                                                                    %Prétraitements de l'image (whitening, resize et déplacement cible)

Afin d'obtenir un modèle à la fois performant et adaptable, nous l'avons soumis à un apprentissage supervisé sous la forme d'une \textbf{régression linéaire multivariée} optimisée par \textbf{descente de gradient}.\\
Pour cela, nous calculons une hypothèse $h_{\theta}$ (équation~\ref{eqn:Hypo}) sur la répartition des stimuli en multipliant chacune des valeurs \textit{x} de l'entrée à un poids $\theta$ qui lui est spécifique.

\begin{equation}
h_{\theta}(x) = \theta^{T}x + b
\label{eqn:Hypo}
\end{equation}

Ces poids sont ensuite optimisés par descente de gradient (équation~\ref{eqn:Grad_desc}), où ils sont comparés aux labels \textit{y} des entrées pour un nombre d'exemples et d'itérations fixées. Le paramètre d'apprentissage $\alpha$ influence très fortement l'apprentissage et sa valeur doit être adaptée pour éviter un sous- ou un sur-apprentissage (révélant respectivement une valeur trop faible ou trop importante).\\

\begin{equation}
\theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^i) - y^i)x_{j}^i
\label{eqn:Grad_desc}
\end{equation}

En parallèle peut être calculé le coût $J(\theta)$ (équation~\ref{eqn:Cost}), dont l'évolution au cours de l'entraînement est un indicateur de l'efficacité de l'apprentissage. Sa valeur devant décroitre au cours du temps, l'optimisation du modèle peut se faire en tentant de la réduire au maximum.

\begin{equation}
J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^i)-y^i)^2
\label{eqn:Cost}
\end{equation}