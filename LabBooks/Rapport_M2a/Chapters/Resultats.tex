% Chapter Template

\chapter{Résultats} % Main chapter title
 
\label{Résultats} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------

Cette partie contient des résultats préliminaires, le modèle étant encore en cours de développement et d'optimisation lors de l'écriture de ce rapport. Les idées émises dans ce chapitre ainsi que le suivant restent pour le moment des hypothèses qui devront nécessairement être confirmées lors de travaux ultérieurs. \\

\section{Apprentissage supervisé}

L'étude d'étalonnage du paramètre d'apprentissage $\alpha$ (équation~\ref{eqn:Grad_desc}) permet de rendre compte de son importance sur l'efficacité de l'apprentissage et du modèle. On peut ainsi observer que certaines valeurs entraînent un sur-apprentissage très important (figures~\ref{fig:benchmark_surApp1} et \ref{fig:benchmark_surApp2}), tandis que d'autres semblent représenter des valeurs utilisables, voire optimales, pour réaliser l'apprentissage (figure~\ref{fig:benchmark_alpha}).\\
Lorsque \textit{détecteur} et \textit{classifieur} sont tous deux entraînés, deux jeux de poids indépendants doivent être optimisés par l'apprentissage. Chaque couche possède ainsi son propre paramètre $\alpha$ (respectivement $\alpha_{detect}$ et $\alpha_{classif}$) et l'on peut donc calculer leurs coûts indépendamments (figure~\ref{fig:logpolar_cost}).\\
On peut observer qu'indépendamment du filtre utilisé et du nombre de couches entraînées, l'apprentissage par descente de gradient permet d'optimiser le modèle, en modifiant graduellement les poids $\theta$. Cette optimisation est révélée par une diminution graduelle du coût, représentant une différence entre la réalité et ce qui est prédit par le modèle.

%----------------------------------------------------------------------------------------

\section{Prédiction de la position}

Après avoir été entraîné, le modèle semble capable de détecter la cible dans son environnement visuel et de prédire précisemment sa position dans l'espace (figure~\ref{fig:saccades_wavelets} et \ref{fig:saccades_logpolar}). L'agent est ensuite capable d'utiliser ces connaissances pour réaliser une saccade jusqu'aux coordonnées prédites de la cible visuelle, ce qui modifie en conséquence sa perception de l'environnement.\\
Une seule saccade n'est pas toujours suffisante pour atteindre la cible (figure~\ref{fig:sacc_nombre}), et le nombre de saccades nécessaires augmente de façon croissante avec la distance initiale de la cible. Il est aussi possible d'observer la présence d'un seuil entre 30 et 40 pixels de distance initiale où le nombre de saccades nécessaires augmente fortement. On peut noter que l'agent ne réalise pas de saccade lorsque la cible apparaît directement dans sa fovéa.\\
L'agent réalise ainsi une série d'observations et d'actions suivant le modèle POMDP (figure~\ref{fig:POMDP}). A chaque action, l'agent rapproche ainsi la cible de sa fovéa, lui permettant d'améliorer la précision de sa prédiction lors de l'observation suivante. 
Le nombre de saccades nécessaires augmente avec la distance initiale de la cible du centre de fixation (figure~\ref{fig:sacc_distance}). \\
Cette relation pourrait provenir de la diminution de l'acuité avec l'excentricité dans la champs visuel (provoquée par le champs rétinien), entraînant une diminution de la précision des prédictions (figure~\ref{fig:err_distance}).\\

%----------------------------------------------------------------------------------------

%\section{Prédiction de la catégorie}

%----------------------------------------------------------------------------------------
