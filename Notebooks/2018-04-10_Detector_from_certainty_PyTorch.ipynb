{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programme principal\n",
    "Ecriture du script py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cert_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Cert_detect.py\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from LogGabor import LogGabor\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Init PyTorch arguments\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST detector from certainty map')\n",
    "parser.add_argument('--batch_size', type=int, default=100, metavar='N',\n",
    "                   help='training batch size used as input (default: 100)')\n",
    "parser.add_argument('--epoch', type=int, default=10, metavar='N',\n",
    "                   help='number of training epochs (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                   help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no_cuda', action='store_true', default=False,\n",
    "                   help='disables use of GPU acceleration (default: False)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                   help='random number seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
    "                   help='how many batches to wait before logging training status (default: 50)')\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available() # check if GPU processing is available\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {} # set some cuda parameters if cuda is activated\n",
    "\n",
    "# Defining how the training data will be loaded\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=True, \n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                batch_size=args.batch_size, \n",
    "                shuffle=True, \n",
    "                **kwargs)\n",
    "\n",
    "# Defining how the test data will be loaded\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                batch_size=args.batch_size, \n",
    "                shuffle=True, \n",
    "                **kwargs)\n",
    "\n",
    "# Defining the categorization neural network\n",
    "class What(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(What, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 50, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(50, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(16820, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 16820)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Defining the localization neural network\n",
    "class Where(nn.Module):\n",
    "    # Defining the layers contained within the network\n",
    "    def __init__(self):\n",
    "        super(Where, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 20, kernel_size=5)  # First convolutional layer        \n",
    "        self.conv2 = nn.Conv1d(20, 50, kernel_size=5) # Second convolutional layer\n",
    "        self.conv2_drop = nn.Dropout()                # Dropout layer (randomly zeroes some of the input elements)\n",
    "        self.fc1 = nn.Linear(5850, 150)                # First linear layer (applies a linear transformation)\n",
    "        self.fc2 = nn.Linear(150, 2)                   # Second linear layer\n",
    "    \n",
    "    # Defining the actions that'll be submitted to the network\n",
    "    def forward(self, x):    \n",
    "        x = F.relu(F.max_pool1d(self.conv1(x),2))                   # F.relu applies the rectified linear unit function element-wise\n",
    "        x = F.relu(F.max_pool1d(self.conv2_drop(self.conv2(x)), 2)) # F.max_pool1d applies 1d max pooling over an input signal\n",
    "        x = x.view(-1, 5850)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def mnist_reshape_128(x, i_off=0, j_off=0):\n",
    "    # Function that take a 28x28 pixels image and integrate it inside a blank 128*128 image\n",
    "    # on coordinates defined by the i_off and j_off arguments\n",
    "    N_pix = 28\n",
    "    assert x.shape == (N_pix,N_pix)\n",
    "    x_translate = np.zeros((N_pix*(128/N_pix), N_pix*(128/N_pix)))\n",
    "    x_translate[(N_pix+22+i_off):(2*N_pix+22+i_off), (N_pix+22+j_off):(2*N_pix+22+j_off)] = x[2,-1]/(np.mean(x[2,-1]))\n",
    "    return x_translate\n",
    "\n",
    "def minmax(value, border):\n",
    "    # Function that take a value and make sure it isn't superior\n",
    "    # to a value defined by the border argument (or inferior of its inverse)\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value\n",
    "\n",
    "def vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y):\n",
    "    # Function that applies the LogPolar filter on an image, decreasing its resolution\n",
    "    # with the excentricity compared to its center.\n",
    "    # N_theta, N_orient, N_scale and N_phase define the filter shape\n",
    "    phi = np.zeros((N_theta, N_orient, N_scale, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    params= {'sf_0':.1, 'B_sf': lg.pe.B_sf, 'theta':np.pi* 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    phase = np.pi/4\n",
    "    edge = lg.normalize(lg.invert(lg.loggabor(N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "    \n",
    "    for i_theta in range(N_theta):\n",
    "        for i_orient in range(N_orient):\n",
    "            for i_scale in range(N_scale):\n",
    "                ecc =  .5**(N_scale - i_scale)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)\n",
    "                y = N_Y/2 + r * np.sin((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)            \n",
    "                for i_phase in range(N_phase):\n",
    "                    params= {'sf_0':sf_0, 'B_sf': lg.pe.B_sf, 'theta':i_theta*np.pi/N_theta, 'B_theta': np.pi/N_theta/2}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    phi[i_theta, i_orient, i_scale, i_phase, :] = lg.normalize(lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel()            \n",
    "    return phi\n",
    "\n",
    "def train_classifier(epoch):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, LABEL) in enumerate(train_loader):\n",
    "        if args.cuda:        \n",
    "            LABEL = LABEL.cuda()           \n",
    "        INPUT = data.min() * np.ones((args.batch_size, 1, 128, 128))\n",
    "\n",
    "        for idx in range(args.batch_size):\n",
    "            i_offset, j_offset = minmax(int(np.random.randn()*0), 2), minmax(int(np.random.randn()*0), 2)\n",
    "            data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "            INPUT[idx, 0, :] = data_reshaped\n",
    "            \n",
    "        INPUT = torch.FloatTensor(INPUT)\n",
    "        #normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "        INPUT, LABEL = Variable(INPUT), Variable(LABEL)\n",
    "        if args.cuda: INPUT = INPUT.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        OUTPUT = model(INPUT)\n",
    "        \n",
    "        loss = F.nll_loss(OUTPUT, LABEL)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tElapsed time: {:.2f} mn'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0], (time.time()-t0)/60))\n",
    "\n",
    "def eval_classifier(epoch):\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss, correct = 0, 0\n",
    "    for batch_idx, (data, LABEL) in enumerate(eval_loader):\n",
    "        if args.cuda: \n",
    "            LABEL = LABEL.cuda() \n",
    "        LABEL = Variable(LABEL)\n",
    "        INPUT = np.zeros((args.batch_size, 1, 128, 128))\n",
    "        \n",
    "        for idx in range(args.batch_size):\n",
    "            i_offset, j_offset = minmax(int(np.random.randn()*0), 2), minmax(int(np.random.randn()*0), 2)\n",
    "            data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "            INPUT[idx,0,:] = data_reshaped\n",
    "            \n",
    "        INPUT = torch.FloatTensor(INPUT)\n",
    "        INPUT = Variable(INPUT)\n",
    "        if args.cuda: INPUT = INPUT.cuda()\n",
    "        \n",
    "        OUTPUT = model(INPUT)\n",
    "        eval_loss += F.nll_loss(OUTPUT, LABEL, size_average=False).data[0]\n",
    "        pred = OUTPUT.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(LABEL.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    eval_loss /= len(eval_loader.dataset)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Elapsed time: {:.2f} mn\\n'.format(eval_loss, \n",
    "                                                                                 correct, \n",
    "                                                                                 len(eval_loader.dataset),\n",
    "                                                                                 100. * correct / len(eval_loader.dataset),\n",
    "                                                                                 (time.time()-t0)/60))\n",
    "         \n",
    "def map_classifier():\n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    accuracy_map = np.zeros((128,128))\n",
    "\n",
    "    for batch_idx, (data, LABEL) in enumerate(eval_loader):\n",
    "        if args.cuda:\n",
    "            LABEL = LABEL.cuda()\n",
    "        LABEL = Variable(LABEL)\n",
    "\n",
    "        for i_offset in range(-30, 30, 1):\n",
    "            for j_offset in range(-30, 30, 1):\n",
    "                pred, correct = 0, 0\n",
    "                INPUT = np.zeros((args.batch_size,1,128,128))\n",
    "                for idx in range(args.batch_size):\n",
    "                    data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "                    INPUT[idx,0,:] =  data_reshaped\n",
    "\n",
    "                INPUT = torch.FloatTensor(INPUT)\n",
    "                INPUT = Variable(INPUT)\n",
    "                if args.cuda:\n",
    "                    INPUT = INPUT.cuda()\n",
    "\n",
    "                OUTPUT = model(INPUT)\n",
    "                pred = OUTPUT.data.max(1, keepdim=True)[1]\n",
    "                correct = pred.eq(LABEL.data.view_as(pred)).sum()\n",
    "                accuracy_map[i_offset+64-1][j_offset+64-1] += (correct / args.batch_size)\n",
    "                if i_offset == 15 and j_offset == 15:\n",
    "                    print(i_offset, j_offset, correct, accuracy_map[i_offset+64-1][j_offset+64-1])\n",
    "\n",
    "                if time.time() - t1 > 30: \n",
    "                    print('i: {}, j: {}, elapsed time: {:.2f} mn'.format(i_offset, j_offset, (time.time()-t0)/60))\n",
    "                    t1 = time.time()\n",
    "        break\n",
    "                \n",
    "    return accuracy_map\n",
    "        \n",
    "            \n",
    "model = What()\n",
    "print('cuda:', args.cuda)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Defining the optimizer that'll train the network\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=args.lr,\n",
    "                      momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "%run Cert_detect.py --epoch=3 --lr=5\n",
    "path = 'Cert_detector.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement + Evaluation\n",
    "Chargement des données si l'entrainement a déjà été réalisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.310353\tElapsed time: 0.02 mn\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.281910\tElapsed time: 0.14 mn\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.300485\tElapsed time: 0.25 mn\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.307182\tElapsed time: 0.37 mn\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.334751\tElapsed time: 0.48 mn\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.314589\tElapsed time: 0.59 mn\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.378581\tElapsed time: 0.71 mn\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.329533\tElapsed time: 0.82 mn\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.325985\tElapsed time: 0.94 mn\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.359250\tElapsed time: 1.05 mn\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.297672\tElapsed time: 1.16 mn\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.334803\tElapsed time: 1.28 mn\n",
      "Test set: Average loss: 2.3221, Accuracy: 982/10000 (10%), Elapsed time: 0.10 mn\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.313906\tElapsed time: 0.00 mn\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.314380\tElapsed time: 0.12 mn\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.321564\tElapsed time: 0.23 mn\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.356605\tElapsed time: 0.35 mn\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.337945\tElapsed time: 0.46 mn\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.274864\tElapsed time: 0.57 mn\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.322968\tElapsed time: 0.69 mn\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.334337\tElapsed time: 0.80 mn\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.309564\tElapsed time: 0.92 mn\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.310578\tElapsed time: 1.03 mn\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.327393\tElapsed time: 1.14 mn\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.311847\tElapsed time: 1.26 mn\n",
      "Test set: Average loss: 2.3239, Accuracy: 1028/10000 (10%), Elapsed time: 0.10 mn\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.326878\tElapsed time: 0.00 mn\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.337278\tElapsed time: 0.12 mn\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.319110\tElapsed time: 0.23 mn\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.310269\tElapsed time: 0.35 mn\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.299656\tElapsed time: 0.46 mn\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.290840\tElapsed time: 0.57 mn\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.342989\tElapsed time: 0.69 mn\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.375972\tElapsed time: 0.80 mn\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.305106\tElapsed time: 0.92 mn\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.319938\tElapsed time: 1.03 mn\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.305176\tElapsed time: 1.14 mn\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.328193\tElapsed time: 1.26 mn\n",
      "Test set: Average loss: 2.3178, Accuracy: 1010/10000 (10%), Elapsed time: 0.10 mn\n",
      "\n",
      "Training saved in Cert_detector.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(path):\n",
    "    print('Loading training values from', path)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "else:\n",
    "    print('Training...')\n",
    "    for epoch in range(1, args.epoch+1):\n",
    "        train_classifier(epoch)\n",
    "        eval_classifier(epoch)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Training saved in', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation seule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11%), Elapsed time: 1.481396 mn\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation...')\n",
    "for epoch in range(1, args.epoch+1):\n",
    "    eval_classifier(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de la carte de certitude\n",
    "Travail en cours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy map construction...\n",
      "i: -15, j: -9, elapsed time: 0.50 mn\n",
      "i: 0, j: -8, elapsed time: 1.00 mn\n",
      "i: 15, j: 11, elapsed time: 1.50 mn\n",
      "15 15 9 0.09\n",
      "i: 24, j: 24, elapsed time: 2.00 mn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f560128f0f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f560171d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Accuracy map construction...')\n",
    "N_pix = 128//2\n",
    "fig, ax = plt.subplots(figsize=(13, 10.725))\n",
    "data = map_classifier()\n",
    "cmap = ax.pcolor(np.arange(-N_pix, N_pix), np.arange(-N_pix, N_pix), data)\n",
    "ax.axis('equal')\n",
    "fig.colorbar(cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
