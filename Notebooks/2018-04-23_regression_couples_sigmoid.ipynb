{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:47.210258Z",
     "start_time": "2018-04-24T09:40:47.118550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy...\n",
      "[[0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]\n",
      " [0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]\n",
      " [0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]\n",
      " ...\n",
      " [0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]\n",
      " [0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]\n",
      " [0.0974 0.0974 0.0974 ... 0.0974 0.0974 0.0974]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = \"MNIST_accuracy.npy\"\n",
    "if os.path.isfile(path):\n",
    "    print('Loading accuracy...')\n",
    "    accuracy =  np.load(path)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparer l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:52.274043Z",
     "start_time": "2018-04-24T09:40:47.211974Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from LogGabor import LogGabor\n",
    "\n",
    "def vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y, rho=1.61803):\n",
    "    phi = np.zeros((N_theta, N_orient, N_scale, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    params= {'sf_0':.1, 'B_sf': lg.pe.B_sf, 'theta':np.pi* 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    phase = np.pi/4\n",
    "    edge = lg.normalize(lg.invert(lg.loggabor(N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "    \n",
    "    for i_theta in range(N_theta):\n",
    "        for i_orient in range(N_orient):\n",
    "            for i_scale in range(N_scale):\n",
    "                ecc =  (1/rho)**(N_scale - i_scale)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)\n",
    "                y = N_Y/2 + r * np.sin((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)            \n",
    "                for i_phase in range(N_phase):\n",
    "                    params= {'sf_0':sf_0, 'B_sf': lg.pe.B_sf, 'theta':i_theta*np.pi/N_theta, 'B_theta': np.pi/N_theta/2}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    phi[i_theta, i_orient, i_scale, i_phase, :] = lg.normalize(lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel()            \n",
    "    return phi\n",
    "\n",
    "N_theta, N_orient, N_scale, N_phase, N_X, N_Y = 6, 12, 5, 2, 128, 128\n",
    "phi = vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y)\n",
    "phi_vector = phi.reshape((N_theta*N_orient*N_scale*N_phase, N_X*N_Y))\n",
    "phi_plus = np.linalg.pinv(phi_vector)\n",
    "\n",
    "energy = (phi**2).sum(axis=(0,3)) \n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((N_orient*N_scale, N_X*N_Y))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "\n",
    "def accuracy_128(i_offset, j_offset):\n",
    "    N_pic = 128\n",
    "    center = (128-55)//2\n",
    "    \n",
    "    accuracy_128 = 0.1 * np.ones((N_pic,N_pic))\n",
    "    accuracy_128[(center+i_offset):(center+55+i_offset),(center+j_offset):(center+55+j_offset)] = accuracy\n",
    "    \n",
    "    accuracy_LP = energy_vector @ np.ravel(accuracy_128)    \n",
    "    return accuracy_LP\n",
    "\n",
    "def mnist_128(data, i_offset, j_offset):\n",
    "    N_pic = 128\n",
    "    center = (128-28)//2\n",
    "    \n",
    "    data_128 = data.min() * np.ones((128,128))\n",
    "    data_128[(center+i_offset):(center+28+i_offset),(center+j_offset):(center+28+j_offset)] = data\n",
    "\n",
    "    data_LP = phi_vector @ np.ravel(data_128)     \n",
    "    return data_LP\n",
    "\n",
    "def couples(data, i_offset, j_offset):\n",
    "    v = mnist_128(data, i_offset, j_offset)\n",
    "    a = accuracy_128(i_offset, j_offset)    \n",
    "    return (v,a)\n",
    "\n",
    "def minmax(value, border):\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value\n",
    "\n",
    "def sigmoid(values):\n",
    "    values = 1 / (1 + ((1 / 0.1) - 1) * np.exp(-values))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du nn apprenant la correspondance input/certitude avec transformées LogPol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:52.327906Z",
     "start_time": "2018-04-24T09:40:52.275811Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from LogGabor import LogGabor\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "sample_size = 100 #quantity of examples that'll be processed\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=True,    #def the dataset as training data \n",
    "                   download=True, #download if dataset not present on disk\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                   batch_size=sample_size, \n",
    "                   shuffle=True)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = F.relu(self.hidden(data))\n",
    "        data = self.predict(data)\n",
    "        data = F.sigmoid(data)\n",
    "        return data\n",
    "    \n",
    "net = Net(n_feature=720, n_hidden=260, n_output=60)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "#loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch_nb, sample_size):\n",
    "    t_start = time.time()\n",
    "    print('Starting training...')\n",
    "    for epoch in range(epoch_nb):\n",
    "        for batch_idx, (data, label) in enumerate(data_loader):\n",
    "            data_v, data_a = np.zeros((sample_size, 1, 720)), np.zeros((sample_size, 1, 60))\n",
    "            for idx in range(sample_size):\n",
    "                i_offset, j_offset = minmax(np.random.randn()*5, 35), minmax(np.random.randn()*5, 35)\n",
    "                v, a = couples(data[idx,0,:], i_offset, j_offset)\n",
    "                data_v[idx,0,:], data_a[idx,0,:] = v, a\n",
    "\n",
    "            data_v, data_a = torch.FloatTensor(data_v), torch.FloatTensor(data_a)\n",
    "            data_v, data_a = Variable(data_v), Variable(data_a)\n",
    "\n",
    "            prediction = net(data_v)\n",
    "            loss = loss_func(prediction, data_a)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Epoch {}: [{}/{}] Loss: {} Time: {:.2f} mn'.format(\n",
    "                    epoch, batch_idx*sample_size, len(data_loader.dataset), \n",
    "                    loss.data.numpy(), (time.time()-t_start)/60))\n",
    "    print('...Training done')\n",
    "    \n",
    "def evaluation():\n",
    "    print('Starting evaluation...')\n",
    "    for batch_idx, (data, label) in enumerate(data_loader):\n",
    "        data_v, data_a = np.zeros((1, 1, 720)), np.zeros((1, 1, 60))\n",
    "\n",
    "        i_offset, j_offset = minmax(np.random.randn()*10, 30), minmax(np.random.randn()*10, 30)\n",
    "        print('i_offset: {}, j_offset: {}'.format(i_offset, j_offset))\n",
    "        v, a = couples(data[0,0,:], i_offset, j_offset)\n",
    "        data_v[0,0,:], data_a[0,0,:] = v, a\n",
    "\n",
    "        data_v, data_a = torch.FloatTensor(data_v), torch.FloatTensor(data_a)\n",
    "        data_v, data_a = Variable(data_v), Variable(data_a)\n",
    "\n",
    "        prediction = net(data_v)\n",
    "        \n",
    "        pred_data = prediction.data.numpy()[-1][-1]\n",
    "\n",
    "        image = energy_plus @ pred_data\n",
    "        image = sigmoid(image)\n",
    "        image_reshaped = image.reshape(128,128)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(13,10.725))\n",
    "        cmap = ax.pcolor(np.arange(-64,64), np.arange(-64,64), image_reshaped)\n",
    "        fig.colorbar(cmap)\n",
    "        plt.axvline(j_offset, c='k'); plt.axhline(i_offset, c='k')\n",
    "        \n",
    "        for i_pred in range(0,128):\n",
    "            for j_pred in range(0,128):\n",
    "                if image_reshaped[i_pred][j_pred] == image_reshaped.max():\n",
    "                    print(i_pred-64, j_pred-64)\n",
    "                    plt.axvline(j_pred-64, c='r'); plt.axhline(i_pred-64, c='r')        \n",
    "        \n",
    "        print('...Evaluation done')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancement apprentissage/évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:52.457899Z",
     "start_time": "2018-04-24T09:40:52.329871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file regression_couples.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "While copying the parameter named hidden.weight, whose dimensions in the model are torch.Size([260, 720]) and whose dimensions in the checkpoint are torch.Size([260, 480]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [260 x 720] and src [260 x 480] to have the same number of elements, but got 187200 and 124800 elements respectively at /Users/soumith/code/builder/wheel/pytorch-src/torch/lib/TH/generic/THTensorCopy.c:86",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-76ab7dc10fb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading file'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    517\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named hidden.weight, whose dimensions in the model are torch.Size([260, 720]) and whose dimensions in the checkpoint are torch.Size([260, 480])."
     ]
    }
   ],
   "source": [
    "path = 'regression_couples.pt'\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    print('Loading file', path)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "else:\n",
    "    print('Training model...')\n",
    "    epoch_nb = 1      #number of training epochs\n",
    "    train(epoch_nb, sample_size)\n",
    "    torch.save(net.state_dict(), path)\n",
    "    print('Model saved at', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:52.458617Z",
     "start_time": "2018-04-24T09:40:47.111Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:40:52.459618Z",
     "start_time": "2018-04-24T09:40:47.112Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10,10,0.2)\n",
    "y = 1 / (1 + ((1 / 0.1) - 1) * np.exp(-x))\n",
    "plt.plot(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
