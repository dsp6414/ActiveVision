{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:42.778431Z",
     "start_time": "2018-05-31T13:00:42.760698Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:54.295525Z",
     "start_time": "2018-05-31T13:00:42.782038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy... min, max= 0.0145 0.9852\n"
     ]
    }
   ],
   "source": [
    "from Where import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-31T13:00:42.738Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model... with lr= 0.002\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.9227764010429382 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37129855155944824 Time: 2.86 mn\n",
      "[20000/60000] Loss: 0.36887815594673157 Time: 5.61 mn\n",
      "[30000/60000] Loss: 0.37104105949401855 Time: 8.35 mn\n",
      "[40000/60000] Loss: 0.3659355938434601 Time: 11.12 mn\n",
      "[50000/60000] Loss: 0.3638758659362793 Time: 13.88 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36652740836143494 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36339154839515686 Time: 2.77 mn\n",
      "[20000/60000] Loss: 0.36216026544570923 Time: 5.51 mn\n",
      "[30000/60000] Loss: 0.36636146903038025 Time: 8.25 mn\n",
      "[40000/60000] Loss: 0.364446222782135 Time: 11.05 mn\n",
      "[50000/60000] Loss: 0.36292943358421326 Time: 13.77 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3616662919521332 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3620888590812683 Time: 2.74 mn\n",
      "[20000/60000] Loss: 0.36342132091522217 Time: 5.47 mn\n",
      "[30000/60000] Loss: 0.3631397783756256 Time: 8.23 mn\n",
      "[40000/60000] Loss: 0.36008647084236145 Time: 11.03 mn\n",
      "[50000/60000] Loss: 0.36075273156166077 Time: 13.85 mn\n",
      "Training model... with lr= 0.003\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.9352086782455444 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37298262119293213 Time: 2.81 mn\n",
      "[20000/60000] Loss: 0.3701348304748535 Time: 5.59 mn\n"
     ]
    }
   ],
   "source": [
    "for lr_ in lr*np.logspace(-1, 1, 9, base=10):\n",
    "    net = Net(n_feature=N_theta*N_azimuth*N_eccentricity*N_phase, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=N_azimuth*N_eccentricity)\n",
    "    # https://pytorch.org/docs/master/optim.html#torch.optim.Adam\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr_)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print('Training model... with lr=', '%.3f' % lr_)\n",
    "    N_epochs = 3\n",
    "    for epoch in range(N_epochs):          #max number of training epochs\n",
    "        train(net, minibatch_size, optimizer=optimizer)                 #starting the learning\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
