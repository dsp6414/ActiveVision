{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T14:08:49.961493Z",
     "start_time": "2018-06-04T14:08:49.923816Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T14:09:31.570342Z",
     "start_time": "2018-06-04T14:08:49.967678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy... min, max= 0.0145 0.9852\n"
     ]
    }
   ],
   "source": [
    "from Where import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancer l'apprentissage ou charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T14:09:31.625148Z",
     "start_time": "2018-06-04T14:09:31.575431Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '2018-05-31_classification_BCELoss_test.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T14:09:31.849122Z",
     "start_time": "2018-06-04T14:09:31.630227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: 2018-05-31_classification_BCELoss_test.pt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {path}\n",
    "#!rm {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:26.370214Z",
     "start_time": "2018-06-04T14:09:31.857729Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.900113582611084 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.39759185910224915 Time: 3.35 mn\n",
      "[20000/60000] Loss: 0.39003849029541016 Time: 6.64 mn\n",
      "[30000/60000] Loss: 0.38892701268196106 Time: 9.88 mn\n",
      "[40000/60000] Loss: 0.3876059651374817 Time: 13.16 mn\n",
      "[50000/60000] Loss: 0.38264894485473633 Time: 16.40 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3850058615207672 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.38355425000190735 Time: 3.17 mn\n",
      "[20000/60000] Loss: 0.38395100831985474 Time: 6.34 mn\n",
      "[30000/60000] Loss: 0.38342738151550293 Time: 9.62 mn\n",
      "[40000/60000] Loss: 0.37626880407333374 Time: 12.93 mn\n",
      "[50000/60000] Loss: 0.3846192955970764 Time: 16.19 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37536895275115967 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37817615270614624 Time: 3.34 mn\n",
      "[20000/60000] Loss: 0.3772825002670288 Time: 6.65 mn\n",
      "[30000/60000] Loss: 0.3776545226573944 Time: 9.89 mn\n",
      "[40000/60000] Loss: 0.3806264400482178 Time: 13.22 mn\n",
      "[50000/60000] Loss: 0.3797738552093506 Time: 16.57 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3771127462387085 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.37561318278312683 Time: 3.40 mn\n",
      "[20000/60000] Loss: 0.3817470669746399 Time: 6.70 mn\n",
      "[30000/60000] Loss: 0.3749593198299408 Time: 10.00 mn\n",
      "[40000/60000] Loss: 0.3768197000026703 Time: 13.35 mn\n",
      "[50000/60000] Loss: 0.37723949551582336 Time: 16.72 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3745673596858978 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.3689018785953522 Time: 3.54 mn\n",
      "[20000/60000] Loss: 0.3713073134422302 Time: 6.98 mn\n",
      "[30000/60000] Loss: 0.3712216913700104 Time: 10.35 mn\n",
      "[40000/60000] Loss: 0.3724808096885681 Time: 13.77 mn\n",
      "[50000/60000] Loss: 0.38083451986312866 Time: 17.22 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3720451295375824 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.37466999888420105 Time: 3.51 mn\n",
      "[20000/60000] Loss: 0.368161678314209 Time: 6.97 mn\n",
      "[30000/60000] Loss: 0.3776911497116089 Time: 10.40 mn\n",
      "[40000/60000] Loss: 0.37493374943733215 Time: 13.83 mn\n",
      "[50000/60000] Loss: 0.3752199113368988 Time: 17.27 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3702426254749298 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3721921145915985 Time: 3.48 mn\n",
      "[20000/60000] Loss: 0.37471258640289307 Time: 6.82 mn\n",
      "[30000/60000] Loss: 0.37350818514823914 Time: 10.18 mn\n",
      "[40000/60000] Loss: 0.3709372282028198 Time: 13.50 mn\n",
      "[50000/60000] Loss: 0.3726809322834015 Time: 16.84 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37505102157592773 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3704746663570404 Time: 3.37 mn\n",
      "[20000/60000] Loss: 0.3714120090007782 Time: 6.79 mn\n",
      "[30000/60000] Loss: 0.3696151375770569 Time: 10.23 mn\n",
      "[40000/60000] Loss: 0.3701205551624298 Time: 13.68 mn\n",
      "[50000/60000] Loss: 0.3685135841369629 Time: 17.12 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37115582823753357 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37218913435935974 Time: 3.47 mn\n",
      "[20000/60000] Loss: 0.3714355230331421 Time: 6.90 mn\n",
      "[30000/60000] Loss: 0.37035349011421204 Time: 10.34 mn\n",
      "[40000/60000] Loss: 0.36898958683013916 Time: 13.85 mn\n",
      "[50000/60000] Loss: 0.36703670024871826 Time: 17.37 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37240204215049744 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3681413531303406 Time: 3.51 mn\n",
      "[20000/60000] Loss: 0.3692440688610077 Time: 6.95 mn\n",
      "[30000/60000] Loss: 0.36847808957099915 Time: 10.28 mn\n",
      "[40000/60000] Loss: 0.36934593319892883 Time: 13.55 mn\n",
      "[50000/60000] Loss: 0.3701552152633667 Time: 16.83 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3691693842411041 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37216517329216003 Time: 3.32 mn\n",
      "[20000/60000] Loss: 0.3696739375591278 Time: 6.51 mn\n",
      "[30000/60000] Loss: 0.37255972623825073 Time: 9.70 mn\n",
      "[40000/60000] Loss: 0.3714125156402588 Time: 12.95 mn\n",
      "[50000/60000] Loss: 0.37147459387779236 Time: 16.28 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37113526463508606 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.37065333127975464 Time: 3.34 mn\n",
      "[20000/60000] Loss: 0.3695108890533447 Time: 6.64 mn\n",
      "[30000/60000] Loss: 0.37022486329078674 Time: 9.98 mn\n",
      "[40000/60000] Loss: 0.3678816556930542 Time: 13.28 mn\n",
      "[50000/60000] Loss: 0.3695899248123169 Time: 16.56 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37292248010635376 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3686317205429077 Time: 3.34 mn\n",
      "[20000/60000] Loss: 0.3690076768398285 Time: 6.65 mn\n",
      "[30000/60000] Loss: 0.3701271414756775 Time: 9.97 mn\n",
      "[40000/60000] Loss: 0.36764785647392273 Time: 13.30 mn\n",
      "[50000/60000] Loss: 0.3655504286289215 Time: 16.61 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36579522490501404 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36861535906791687 Time: 3.35 mn\n",
      "[20000/60000] Loss: 0.3719557523727417 Time: 6.64 mn\n",
      "[30000/60000] Loss: 0.3682438135147095 Time: 9.92 mn\n",
      "[40000/60000] Loss: 0.3684419095516205 Time: 13.05 mn\n",
      "[50000/60000] Loss: 0.37044230103492737 Time: 16.41 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3682667911052704 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.3698623478412628 Time: 3.54 mn\n",
      "[20000/60000] Loss: 0.37216705083847046 Time: 7.03 mn\n",
      "[30000/60000] Loss: 0.3668430745601654 Time: 10.51 mn\n",
      "[40000/60000] Loss: 0.37018540501594543 Time: 13.99 mn\n",
      "[50000/60000] Loss: 0.3701784908771515 Time: 17.44 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3685857653617859 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3696445822715759 Time: 3.23 mn\n",
      "[20000/60000] Loss: 0.36844602227211 Time: 6.43 mn\n",
      "[30000/60000] Loss: 0.3685748279094696 Time: 9.65 mn\n",
      "[40000/60000] Loss: 0.37028780579566956 Time: 12.87 mn\n",
      "[50000/60000] Loss: 0.37004518508911133 Time: 16.09 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36576756834983826 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36985835433006287 Time: 3.22 mn\n",
      "[20000/60000] Loss: 0.36754173040390015 Time: 6.41 mn\n",
      "[30000/60000] Loss: 0.3671766519546509 Time: 9.48 mn\n",
      "[40000/60000] Loss: 0.36687231063842773 Time: 12.35 mn\n",
      "[50000/60000] Loss: 0.3690597712993622 Time: 15.28 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3686453104019165 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3695308566093445 Time: 3.01 mn\n",
      "[20000/60000] Loss: 0.368640273809433 Time: 5.96 mn\n",
      "[30000/60000] Loss: 0.3661785125732422 Time: 8.90 mn\n",
      "[40000/60000] Loss: 0.36803969740867615 Time: 11.84 mn\n",
      "[50000/60000] Loss: 0.3678828775882721 Time: 14.78 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36948010325431824 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36572644114494324 Time: 2.99 mn\n",
      "[20000/60000] Loss: 0.36711424589157104 Time: 5.93 mn\n",
      "[30000/60000] Loss: 0.36619722843170166 Time: 8.86 mn\n",
      "[40000/60000] Loss: 0.3670680820941925 Time: 11.79 mn\n",
      "[50000/60000] Loss: 0.3708665668964386 Time: 14.71 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36501073837280273 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36417511105537415 Time: 2.97 mn\n",
      "[20000/60000] Loss: 0.3690011501312256 Time: 5.91 mn\n",
      "[30000/60000] Loss: 0.3667192757129669 Time: 8.83 mn\n",
      "[40000/60000] Loss: 0.365660160779953 Time: 11.46 mn\n",
      "[50000/60000] Loss: 0.36815229058265686 Time: 14.01 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3615100681781769 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.36919116973876953 Time: 2.28 mn\n",
      "[20000/60000] Loss: 0.36985766887664795 Time: 4.53 mn\n",
      "[30000/60000] Loss: 0.3679240942001343 Time: 6.76 mn\n",
      "[40000/60000] Loss: 0.3647831976413727 Time: 9.01 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50000/60000] Loss: 0.3647119998931885 Time: 11.26 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.363523930311203 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.36625802516937256 Time: 2.07 mn\n",
      "[20000/60000] Loss: 0.36702054738998413 Time: 4.11 mn\n",
      "[30000/60000] Loss: 0.3671985864639282 Time: 6.14 mn\n",
      "[40000/60000] Loss: 0.36718955636024475 Time: 8.00 mn\n",
      "[50000/60000] Loss: 0.3641718327999115 Time: 9.87 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36759498715400696 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.3648873567581177 Time: 1.73 mn\n",
      "[20000/60000] Loss: 0.367784708738327 Time: 3.45 mn\n",
      "[30000/60000] Loss: 0.36828580498695374 Time: 5.06 mn\n",
      "[40000/60000] Loss: 0.3677597939968109 Time: 6.49 mn\n",
      "[50000/60000] Loss: 0.36844855546951294 Time: 7.93 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3682379424571991 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36638203263282776 Time: 1.45 mn\n",
      "[20000/60000] Loss: 0.3655144274234772 Time: 2.88 mn\n",
      "[30000/60000] Loss: 0.3684966266155243 Time: 4.29 mn\n",
      "[40000/60000] Loss: 0.36826375126838684 Time: 5.61 mn\n",
      "[50000/60000] Loss: 0.36368006467819214 Time: 6.85 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36678361892700195 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3670464754104614 Time: 1.20 mn\n",
      "[20000/60000] Loss: 0.3674417734146118 Time: 2.30 mn\n",
      "[30000/60000] Loss: 0.3669212758541107 Time: 3.41 mn\n",
      "[40000/60000] Loss: 0.36782848834991455 Time: 4.51 mn\n",
      "[50000/60000] Loss: 0.3692173957824707 Time: 5.62 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36790207028388977 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3662411570549011 Time: 1.12 mn\n",
      "[20000/60000] Loss: 0.36693447828292847 Time: 2.24 mn\n",
      "[30000/60000] Loss: 0.3651329278945923 Time: 3.35 mn\n",
      "[40000/60000] Loss: 0.3671968877315521 Time: 4.45 mn\n",
      "[50000/60000] Loss: 0.3655785322189331 Time: 5.54 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36682331562042236 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3656907081604004 Time: 1.03 mn\n",
      "[20000/60000] Loss: 0.365718811750412 Time: 2.05 mn\n",
      "[30000/60000] Loss: 0.3634462356567383 Time: 3.08 mn\n",
      "[40000/60000] Loss: 0.3639325499534607 Time: 4.09 mn\n",
      "[50000/60000] Loss: 0.3650565445423126 Time: 5.11 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3633514940738678 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36857643723487854 Time: 1.01 mn\n",
      "[20000/60000] Loss: 0.36457711458206177 Time: 1.87 mn\n",
      "[30000/60000] Loss: 0.3665182888507843 Time: 2.71 mn\n",
      "[40000/60000] Loss: 0.36476752161979675 Time: 3.54 mn\n",
      "[50000/60000] Loss: 0.366006463766098 Time: 4.37 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3628769814968109 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36843228340148926 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36412349343299866 Time: 1.67 mn\n",
      "[30000/60000] Loss: 0.36632564663887024 Time: 2.50 mn\n",
      "[40000/60000] Loss: 0.36752599477767944 Time: 3.34 mn\n",
      "[50000/60000] Loss: 0.36844590306282043 Time: 4.17 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36582452058792114 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36539900302886963 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36810004711151123 Time: 1.67 mn\n",
      "[30000/60000] Loss: 0.36437708139419556 Time: 2.50 mn\n",
      "[40000/60000] Loss: 0.36503976583480835 Time: 3.34 mn\n",
      "[50000/60000] Loss: 0.36728596687316895 Time: 4.17 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3652079701423645 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3682039976119995 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36765554547309875 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.365840882062912 Time: 2.51 mn\n",
      "[40000/60000] Loss: 0.3618541657924652 Time: 3.34 mn\n",
      "[50000/60000] Loss: 0.3636627197265625 Time: 4.18 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36584898829460144 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3632815182209015 Time: 0.78 mn\n",
      "[20000/60000] Loss: 0.3648185133934021 Time: 1.54 mn\n",
      "[30000/60000] Loss: 0.36655181646347046 Time: 2.30 mn\n",
      "[40000/60000] Loss: 0.3667445182800293 Time: 3.06 mn\n",
      "[50000/60000] Loss: 0.3607622981071472 Time: 3.82 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3641901910305023 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3660838305950165 Time: 0.69 mn\n",
      "[20000/60000] Loss: 0.366414338350296 Time: 1.37 mn\n",
      "[30000/60000] Loss: 0.36388880014419556 Time: 2.01 mn\n",
      "[40000/60000] Loss: 0.36386042833328247 Time: 2.64 mn\n",
      "[50000/60000] Loss: 0.36620014905929565 Time: 3.27 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3665997087955475 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36282649636268616 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36486396193504333 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3659968674182892 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3695496618747711 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36576026678085327 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3673974573612213 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3648588955402374 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36869874596595764 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3613862097263336 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.361618310213089 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36520326137542725 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3666536509990692 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3656565845012665 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36482855677604675 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36957770586013794 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3667237162590027 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36445310711860657 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36188533902168274 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36640074849128723 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3627104163169861 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36459478735923767 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36406198143959045 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3637615144252777 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3677823841571808 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3655466139316559 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.363818496465683 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3624162971973419 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3643438518047333 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36451590061187744 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3669026494026184 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36261889338493347 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36731308698654175 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3690033257007599 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3665711283683777 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3634023666381836 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36400434374809265 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36417993903160095 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3615986704826355 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3648841679096222 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36391136050224304 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36335423588752747 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3632866144180298 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3674316704273224 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3690676987171173 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.367454469203949 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3654077649116516 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36234137415885925 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36732983589172363 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3674601912498474 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3640821874141693 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3690479099750519 Time: 1.90 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40000/60000] Loss: 0.3686598837375641 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36797550320625305 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3629790246486664 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36569198966026306 Time: 0.63 mn\n",
      "[20000/60000] Loss: 0.3639248311519623 Time: 1.26 mn\n",
      "[30000/60000] Loss: 0.36389103531837463 Time: 1.89 mn\n",
      "[40000/60000] Loss: 0.3660743534564972 Time: 2.52 mn\n",
      "[50000/60000] Loss: 0.3648095428943634 Time: 3.15 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3635510504245758 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36372435092926025 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3639417886734009 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3629845082759857 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3664565682411194 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36479535698890686 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.364968866109848 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.362024188041687 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36544111371040344 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3644391894340515 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36607030034065247 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36456847190856934 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36511385440826416 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3623845875263214 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36895281076431274 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3635420501232147 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3622523546218872 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36057430505752563 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3661741614341736 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36432769894599915 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36066102981567383 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3610284626483917 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36381545662879944 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36824658513069153 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.365210622549057 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3678092956542969 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3681570589542389 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3599790930747986 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36308398842811584 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36754289269447327 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3629664182662964 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36483579874038696 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.364713191986084 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36355113983154297 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36404308676719666 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36375871300697327 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36476051807403564 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3659895062446594 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36579078435897827 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3642258942127228 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3619731664657593 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3618590831756592 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3596513271331787 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3639615476131439 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36347973346710205 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.362442284822464 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3597630262374878 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3642064929008484 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3628109097480774 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3613278269767761 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36428406834602356 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3668077886104584 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3676571249961853 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.361057847738266 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36237168312072754 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3630351126194 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3626675307750702 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36242640018463135 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36329129338264465 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3651762306690216 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3599391281604767 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36298447847366333 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3623318672180176 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36258992552757263 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3631955683231354 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3638729155063629 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3630424439907074 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.363902747631073 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3623473644256592 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3655543923377991 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3613383173942566 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36411839723587036 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3659426271915436 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36513423919677734 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3590262532234192 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.366588294506073 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3645944595336914 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36523133516311646 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3620828092098236 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36300408840179443 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3630552589893341 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3668045997619629 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36444926261901855 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36484378576278687 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3598928451538086 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36290350556373596 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3622300922870636 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3632214665412903 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3597373962402344 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3631940186023712 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3642148971557617 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36458277702331543 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3623710572719574 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36508238315582275 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3647806644439697 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3641993999481201 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36193010210990906 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36086875200271606 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.362086683511734 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36604270339012146 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36231157183647156 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3640235960483551 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36888012290000916 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.363112211227417 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3670154809951782 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36087873578071594 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3651670515537262 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.363849014043808 Time: 3.17 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3605457544326782 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36546263098716736 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3630318343639374 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3621232807636261 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3636547029018402 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3630926311016083 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3625846803188324 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3638606369495392 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36150112748146057 Time: 1.27 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30000/60000] Loss: 0.3639179766178131 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3637666702270508 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.363530695438385 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.364795982837677 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3620877265930176 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3626142740249634 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3624861240386963 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36383530497550964 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3595615029335022 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3639960289001465 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3660086691379547 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3621629774570465 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36397987604141235 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3614087402820587 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36480268836021423 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.360275536775589 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36213696002960205 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3618127405643463 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3614113926887512 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3654291033744812 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3661539554595947 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3642270267009735 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3600896894931793 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3608951270580292 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3657061755657196 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3663935959339142 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3633672893047333 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3644867241382599 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3602507710456848 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36638087034225464 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36669379472732544 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36422625184059143 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3654105067253113 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36402764916419983 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36411333084106445 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36292392015457153 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3641565144062042 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3619951605796814 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3642440140247345 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36202847957611084 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3635546863079071 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36681050062179565 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36605989933013916 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36744818091392517 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36377575993537903 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3607061803340912 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3616575300693512 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3651708960533142 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3596375584602356 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36002057790756226 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36407870054244995 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3649243712425232 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3604576587677002 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3601807653903961 Time: 1.26 mn\n",
      "[30000/60000] Loss: 0.3659506142139435 Time: 1.89 mn\n",
      "[40000/60000] Loss: 0.3641265630722046 Time: 2.52 mn\n",
      "[50000/60000] Loss: 0.3638545572757721 Time: 3.15 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3627733290195465 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3620110750198364 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36610475182533264 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3649260103702545 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36561593413352966 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36311018466949463 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3604127764701843 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3608306646347046 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3635123372077942 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36048057675361633 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3616783916950226 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36251407861709595 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3620876669883728 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36745786666870117 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3581269383430481 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3595389723777771 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3646423816680908 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3620767593383789 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3621593415737152 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3621014654636383 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36126798391342163 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36209288239479065 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36270156502723694 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3615216314792633 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3656167984008789 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36056816577911377 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.35889294743537903 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3646560609340668 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36141932010650635 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3622308075428009 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36368268728256226 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36126193404197693 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3624383211135864 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36070460081100464 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36091482639312744 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36471542716026306 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3621865212917328 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.362287700176239 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3614853322505951 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36445534229278564 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3648245930671692 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36384329199790955 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3651629090309143 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36416736245155334 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3627069592475891 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36386820673942566 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36315733194351196 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3621397018432617 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36714598536491394 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3651719391345978 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3648815453052521 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36418014764785767 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3613432049751282 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36353084444999695 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3621547222137451 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3632577955722809 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36112043261528015 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3649461269378662 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3613511025905609 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36256587505340576 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36149635910987854 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3610972464084625 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3612217605113983 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.35917866230010986 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3606550097465515 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36343711614608765 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.362432062625885 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36325570940971375 Time: 0.64 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000/60000] Loss: 0.3640254735946655 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36070337891578674 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.359689325094223 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36265888810157776 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3603355288505554 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3605997860431671 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36206167936325073 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36328157782554626 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.363910436630249 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36181876063346863 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36193597316741943 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3639829158782959 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3625158667564392 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3624575734138489 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3626447916030884 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3615974187850952 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3610646426677704 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3603420555591583 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3614416718482971 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3641677796840668 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36490508913993835 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3637792766094208 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36646679043769836 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36492374539375305 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3621557056903839 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3641595244407654 Time: 1.89 mn\n",
      "[40000/60000] Loss: 0.3616390526294708 Time: 2.52 mn\n",
      "[50000/60000] Loss: 0.36329278349876404 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36030319333076477 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3626205623149872 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3627898097038269 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36186423897743225 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3611459732055664 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36083802580833435 Time: 3.17 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3634478747844696 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.361704558134079 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36212530732154846 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3636989891529083 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36415866017341614 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.362783282995224 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.362384557723999 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3644120693206787 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36165159940719604 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36118820309638977 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.363326758146286 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3596610128879547 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36415550112724304 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36164236068725586 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36428752541542053 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.35735785961151123 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.3601238429546356 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3633631765842438 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3644445240497589 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36097267270088196 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3615451753139496 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36171114444732666 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36411479115486145 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36003443598747253 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.363094300031662 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3618907034397125 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36204811930656433 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3635779917240143 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36113396286964417 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.3570922315120697 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36412519216537476 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.35964006185531616 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36384543776512146 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.364481121301651 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.358553022146225 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.364779531955719 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36266419291496277 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3611031770706177 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36060184240341187 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36006614565849304 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36147886514663696 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36304980516433716 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3657051920890808 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36343255639076233 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.35922208428382874 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.36410099267959595 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36377736926078796 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36443743109703064 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3603421151638031 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3601374328136444 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3640478849411011 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3632340133190155 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36225268244743347 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36254769563674927 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36354315280914307 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3627777099609375 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.36315977573394775 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3600687086582184 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36103156208992004 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36221978068351746 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36351096630096436 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3638574779033661 Time: 0.64 mn\n",
      "[20000/60000] Loss: 0.3610273599624634 Time: 1.27 mn\n",
      "[30000/60000] Loss: 0.3652576208114624 Time: 1.90 mn\n",
      "[40000/60000] Loss: 0.36287128925323486 Time: 2.53 mn\n",
      "[50000/60000] Loss: 0.36169421672821045 Time: 3.16 mn\n",
      "Model saved at 2018-05-31_classification_BCELoss_test.pt\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(path):\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    print('Loading file', path)\n",
    "else:\n",
    "    print('Training model...')\n",
    "    N_epochs = 100\n",
    "    for epoch in range(N_epochs):          #max number of training epochs\n",
    "        net = train(net, minibatch_size)                 #starting the learning\n",
    "        torch.save(net.state_dict(), path) #save the neural network state\n",
    "        print('Model saved at', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.446149Z",
     "start_time": "2018-06-05T02:24:26.372366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Loading accuracy... min, max= 0.0145 0.9852\n"
     ]
    }
   ],
   "source": [
    "(data, label) = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.465536Z",
     "start_time": "2018-06-05T02:24:42.448230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(data[idx, 0, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.517737Z",
     "start_time": "2018-06-05T02:24:42.467115Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_eccentricty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e180409d7bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_azimuth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_eccentricty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'N_eccentricty' is not defined"
     ]
    }
   ],
   "source": [
    "retina = vectorization(N_theta, N_azimuth, N_eccentricty, N_phase, N_X, N_Y, rho)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancer l'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.518472Z",
     "start_time": "2018-06-04T14:08:49.904Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_test = 10\n",
    "\n",
    "for _ in range(N_test):\n",
    "    eval_sacc()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.519476Z",
     "start_time": "2018-06-04T14:08:49.912Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(N_test):\n",
    "    eval_sacc(fig_type='log')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.520745Z",
     "start_time": "2018-06-04T14:08:49.918Z"
    }
   },
   "outputs": [],
   "source": [
    "eccentricty, azimuth = np.meshgrid(np.linspace(0, 1, N_eccentricty+1), np.linspace(-np.pi, np.pi, N_azimuth+1))\n",
    "eccentricty.shape, azimuth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T02:24:42.521893Z",
     "start_time": "2018-06-04T14:08:49.924Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(plt.pcolor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
