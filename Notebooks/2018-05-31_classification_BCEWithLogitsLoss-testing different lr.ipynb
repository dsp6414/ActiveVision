{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:06:50.041735Z",
     "start_time": "2018-06-06T15:06:49.998542Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:08:04.772995Z",
     "start_time": "2018-06-06T15:06:50.048139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy... min, max= 0.0145 0.9852\n",
      "n_hidden1 80  / n_hidden2 200\n"
     ]
    }
   ],
   "source": [
    "from Where import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T21:53:39.643256Z",
     "start_time": "2018-06-06T15:08:04.795069Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model... with lr= 0.005\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6944959759712219 Time: 0.07 mn\n",
      "[10000/60000] Loss: 0.688113272190094 Time: 6.66 mn\n",
      "[20000/60000] Loss: 0.6826991438865662 Time: 13.16 mn\n",
      "[30000/60000] Loss: 0.673717200756073 Time: 19.47 mn\n",
      "[40000/60000] Loss: 0.6657770276069641 Time: 24.62 mn\n",
      "[50000/60000] Loss: 0.6543231010437012 Time: 28.87 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6409032344818115 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.6191826462745667 Time: 4.30 mn\n",
      "[20000/60000] Loss: 0.5916801691055298 Time: 8.58 mn\n",
      "[30000/60000] Loss: 0.5660898685455322 Time: 12.87 mn\n",
      "[40000/60000] Loss: 0.5334458351135254 Time: 17.17 mn\n",
      "[50000/60000] Loss: 0.49611881375312805 Time: 21.45 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.4645065367221832 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.4681496322154999 Time: 4.28 mn\n",
      "[20000/60000] Loss: 0.43079081177711487 Time: 8.55 mn\n",
      "[30000/60000] Loss: 0.4290982484817505 Time: 12.81 mn\n",
      "[40000/60000] Loss: 0.4332314431667328 Time: 17.07 mn\n",
      "[50000/60000] Loss: 0.41803595423698425 Time: 21.33 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.4285328686237335 Time: 0.04 mn\n",
      "[10000/60000] Loss: 0.4133312404155731 Time: 4.28 mn\n",
      "[20000/60000] Loss: 0.41198644042015076 Time: 8.54 mn\n",
      "[30000/60000] Loss: 0.41407889127731323 Time: 12.81 mn\n",
      "[40000/60000] Loss: 0.4054229259490967 Time: 17.04 mn\n",
      "[50000/60000] Loss: 0.40626996755599976 Time: 21.29 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3975953757762909 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.40740957856178284 Time: 2.89 mn\n",
      "[20000/60000] Loss: 0.41688355803489685 Time: 5.77 mn\n",
      "[30000/60000] Loss: 0.4037688374519348 Time: 8.63 mn\n",
      "[40000/60000] Loss: 0.40201041102409363 Time: 10.99 mn\n",
      "[50000/60000] Loss: 0.40085747838020325 Time: 12.55 mn\n",
      "Training model... with lr= 0.016\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6934353113174438 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.6730780005455017 Time: 2.69 mn\n",
      "[20000/60000] Loss: 0.6341360211372375 Time: 5.59 mn\n",
      "[30000/60000] Loss: 0.548439085483551 Time: 8.53 mn\n",
      "[40000/60000] Loss: 0.46024343371391296 Time: 11.55 mn\n",
      "[50000/60000] Loss: 0.4251355528831482 Time: 14.61 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.4148070812225342 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.4038376808166504 Time: 3.10 mn\n",
      "[20000/60000] Loss: 0.39937493205070496 Time: 6.14 mn\n",
      "[30000/60000] Loss: 0.3915126323699951 Time: 9.21 mn\n",
      "[40000/60000] Loss: 0.4092257022857666 Time: 12.22 mn\n",
      "[50000/60000] Loss: 0.39580342173576355 Time: 15.18 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.39212778210639954 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.39216482639312744 Time: 2.88 mn\n",
      "[20000/60000] Loss: 0.3967747390270233 Time: 5.71 mn\n",
      "[30000/60000] Loss: 0.3942852318286896 Time: 8.54 mn\n",
      "[40000/60000] Loss: 0.38945454359054565 Time: 11.35 mn\n",
      "[50000/60000] Loss: 0.3921873867511749 Time: 14.17 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.39579713344573975 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.386883944272995 Time: 2.83 mn\n",
      "[20000/60000] Loss: 0.3873591721057892 Time: 5.62 mn\n",
      "[30000/60000] Loss: 0.3882443606853485 Time: 8.41 mn\n",
      "[40000/60000] Loss: 0.38776054978370667 Time: 11.20 mn\n",
      "[50000/60000] Loss: 0.38856202363967896 Time: 14.01 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.38621586561203003 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.38667964935302734 Time: 1.51 mn\n",
      "[20000/60000] Loss: 0.3868331015110016 Time: 3.00 mn\n",
      "[30000/60000] Loss: 0.38554808497428894 Time: 4.49 mn\n",
      "[40000/60000] Loss: 0.3822866678237915 Time: 5.98 mn\n",
      "[50000/60000] Loss: 0.38368743658065796 Time: 7.48 mn\n",
      "Training model... with lr= 0.050\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6993361711502075 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.5957559943199158 Time: 1.50 mn\n",
      "[20000/60000] Loss: 0.4218881130218506 Time: 3.03 mn\n",
      "[30000/60000] Loss: 0.4099120795726776 Time: 4.52 mn\n",
      "[40000/60000] Loss: 0.40031394362449646 Time: 6.04 mn\n",
      "[50000/60000] Loss: 0.38924646377563477 Time: 7.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3950205147266388 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3903183043003082 Time: 1.59 mn\n",
      "[20000/60000] Loss: 0.39743003249168396 Time: 3.15 mn\n",
      "[30000/60000] Loss: 0.38179388642311096 Time: 4.73 mn\n",
      "[40000/60000] Loss: 0.3873708248138428 Time: 6.34 mn\n",
      "[50000/60000] Loss: 0.3868303894996643 Time: 7.90 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3838205337524414 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.38572365045547485 Time: 2.12 mn\n",
      "[20000/60000] Loss: 0.38595423102378845 Time: 5.03 mn\n",
      "[30000/60000] Loss: 0.38561782240867615 Time: 7.88 mn\n",
      "[40000/60000] Loss: 0.3785060942173004 Time: 10.75 mn\n",
      "[50000/60000] Loss: 0.38128089904785156 Time: 13.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.38885805010795593 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.38422316312789917 Time: 2.83 mn\n",
      "[20000/60000] Loss: 0.37455204129219055 Time: 5.64 mn\n",
      "[30000/60000] Loss: 0.3782604932785034 Time: 8.44 mn\n",
      "[40000/60000] Loss: 0.380728542804718 Time: 11.24 mn\n",
      "[50000/60000] Loss: 0.379362016916275 Time: 14.04 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.38029664754867554 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.38147449493408203 Time: 2.89 mn\n",
      "[20000/60000] Loss: 0.37762969732284546 Time: 5.79 mn\n",
      "[30000/60000] Loss: 0.37682974338531494 Time: 8.67 mn\n",
      "[40000/60000] Loss: 0.3752213716506958 Time: 11.57 mn\n",
      "[50000/60000] Loss: 0.3781634569168091 Time: 14.53 mn\n",
      "Training model... with lr= 0.158\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.693718671798706 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.4008580148220062 Time: 3.04 mn\n",
      "[20000/60000] Loss: 0.3813451826572418 Time: 6.06 mn\n",
      "[30000/60000] Loss: 0.38086217641830444 Time: 9.04 mn\n",
      "[40000/60000] Loss: 0.38026854395866394 Time: 11.97 mn\n",
      "[50000/60000] Loss: 0.38240280747413635 Time: 14.90 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37759333848953247 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3772493600845337 Time: 2.13 mn\n",
      "[20000/60000] Loss: 0.37928810715675354 Time: 3.66 mn\n",
      "[30000/60000] Loss: 0.37785428762435913 Time: 5.19 mn\n",
      "[40000/60000] Loss: 0.3713729977607727 Time: 6.70 mn\n",
      "[50000/60000] Loss: 0.37393489480018616 Time: 8.28 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37114217877388 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.3713180422782898 Time: 1.58 mn\n",
      "[20000/60000] Loss: 0.3726193904876709 Time: 3.13 mn\n",
      "[30000/60000] Loss: 0.37158188223838806 Time: 4.66 mn\n",
      "[40000/60000] Loss: 0.37132489681243896 Time: 6.21 mn\n",
      "[50000/60000] Loss: 0.3695075213909149 Time: 7.77 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3730446398258209 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.3729616701602936 Time: 1.56 mn\n",
      "[20000/60000] Loss: 0.36464619636535645 Time: 3.11 mn\n",
      "[30000/60000] Loss: 0.3692828416824341 Time: 4.67 mn\n",
      "[40000/60000] Loss: 0.36675825715065 Time: 6.21 mn\n",
      "[50000/60000] Loss: 0.37107187509536743 Time: 7.80 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3666634261608124 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.36757081747055054 Time: 1.57 mn\n",
      "[20000/60000] Loss: 0.3717728555202484 Time: 3.14 mn\n",
      "[30000/60000] Loss: 0.3655618131160736 Time: 5.07 mn\n",
      "[40000/60000] Loss: 0.36964473128318787 Time: 7.98 mn\n",
      "[50000/60000] Loss: 0.36718475818634033 Time: 10.84 mn\n",
      "Training model... with lr= 0.500\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6966850161552429 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.38730388879776 Time: 2.95 mn\n",
      "[20000/60000] Loss: 0.3758760690689087 Time: 5.83 mn\n",
      "[30000/60000] Loss: 0.3741488456726074 Time: 8.77 mn\n",
      "[40000/60000] Loss: 0.36876872181892395 Time: 11.83 mn\n",
      "[50000/60000] Loss: 0.37306448817253113 Time: 14.87 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3681659400463104 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.3690561056137085 Time: 2.92 mn\n",
      "[20000/60000] Loss: 0.37068819999694824 Time: 5.79 mn\n",
      "[30000/60000] Loss: 0.3661762475967407 Time: 8.65 mn\n",
      "[40000/60000] Loss: 0.36506831645965576 Time: 11.61 mn\n",
      "[50000/60000] Loss: 0.3646443784236908 Time: 14.42 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36322036385536194 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36293405294418335 Time: 2.91 mn\n",
      "[20000/60000] Loss: 0.3653145432472229 Time: 5.76 mn\n",
      "[30000/60000] Loss: 0.3649121820926666 Time: 8.62 mn\n",
      "[40000/60000] Loss: 0.36552777886390686 Time: 11.46 mn\n",
      "[50000/60000] Loss: 0.36401358246803284 Time: 14.34 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3612156808376312 Time: 0.03 mn\n",
      "[10000/60000] Loss: 0.36135172843933105 Time: 2.96 mn\n",
      "[20000/60000] Loss: 0.36046910285949707 Time: 5.91 mn\n",
      "[30000/60000] Loss: 0.3621492087841034 Time: 8.19 mn\n",
      "[40000/60000] Loss: 0.3587338328361511 Time: 9.80 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50000/60000] Loss: 0.3593831956386566 Time: 11.39 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36270377039909363 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.3613034784793854 Time: 1.58 mn\n",
      "[20000/60000] Loss: 0.3594529330730438 Time: 3.13 mn\n",
      "[30000/60000] Loss: 0.3632308840751648 Time: 4.69 mn\n",
      "[40000/60000] Loss: 0.3617592453956604 Time: 6.26 mn\n",
      "[50000/60000] Loss: 0.3625517189502716 Time: 7.80 mn\n"
     ]
    }
   ],
   "source": [
    "N_epochs = 5\n",
    "\n",
    "for lr_ in lr*np.logspace(-1, 1, 5, base=10):\n",
    "    net = Net(n_feature=N_theta*N_azimuth*N_eccentricity*N_phase, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=N_azimuth*N_eccentricity)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr_)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print('Training model... with lr=', '%.3f' % lr_)\n",
    "    for epoch in range(N_epochs):                       #max number of training epochs\n",
    "        train(net, minibatch_size, optimizer=optimizer) #starting the learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
