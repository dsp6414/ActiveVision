{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Cert_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Cert_detect.py\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from LogGabor import LogGabor\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Init PyTorch arguments\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST detector from certainty map')\n",
    "parser.add_argument('--batch_size', type=int, default=100, metavar='N',\n",
    "                   help='training batch size used as input (default: 100)')\n",
    "parser.add_argument('--epoch', type=int, default=10, metavar='N',\n",
    "                   help='number of training epochs (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                   help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no_cuda', action='store_true', default=False,\n",
    "                   help='disables use of GPU acceleration (default: False)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                   help='random number seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
    "                   help='how many batches to wait before logging training status (default: 50)')\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available() # check if GPU processing is available\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {} # set some cuda parameters if cuda is activated\n",
    "\n",
    "# Defining how the training data will be loaded\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=True, \n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                batch_size=args.batch_size, \n",
    "                shuffle=True, \n",
    "                **kwargs)\n",
    "\n",
    "# Defining how the test data will be loaded\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                batch_size=args.batch_size, \n",
    "                shuffle=True, \n",
    "                **kwargs)\n",
    "\n",
    "# Defining the categorization neural network\n",
    "class What(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(What, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(16820, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 16820)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Defining the localization neural network\n",
    "class Where(nn.Module):\n",
    "    # Defining the layers contained within the network\n",
    "    def __init__(self):\n",
    "        super(Where, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 20, kernel_size=5)  # First convolutional layer        \n",
    "        self.conv2 = nn.Conv1d(20, 50, kernel_size=5) # Second convolutional layer\n",
    "        self.conv2_drop = nn.Dropout()                # Dropout layer (randomly zeroes some of the input elements)\n",
    "        self.fc1 = nn.Linear(5850, 50)                # First linear layer (applies a linear transformation)\n",
    "        self.fc2 = nn.Linear(50, 2)                   # Second linear layer\n",
    "    \n",
    "    # Defining the actions that'll be submitted to the network\n",
    "    def forward(self, x):    \n",
    "        x = F.relu(F.max_pool1d(self.conv1(x),2))                   # F.relu applies the rectified linear unit function element-wise\n",
    "        x = F.relu(F.max_pool1d(self.conv2_drop(self.conv2(x)), 2)) # F.max_pool1d applies 1d max pooling over an input signal\n",
    "        x = x.view(-1, 5850)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def mnist_reshape_128(x, i_off=0, j_off=0):\n",
    "    # Function that take a 28x28 pixels image and integrate it inside a blank 128*128 image\n",
    "    # on coordinates defined by the i_off and j_off arguments\n",
    "    N_pix = 28\n",
    "    assert x.shape == (N_pix,N_pix)\n",
    "    x_translate = np.zeros((N_pix*(128/N_pix), N_pix*(128/N_pix)))\n",
    "    x_translate[(N_pix+22+i_off):(2*N_pix+22+i_off), (N_pix+22+j_off):(2*N_pix+22+j_off)] = x[2,-1]\n",
    "    return x_translate\n",
    "\n",
    "def minmax(value, border):\n",
    "    # Function that take a value and make sure it isn't superior\n",
    "    # to a value defined by the border argument (or inferior of its inverse)\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value\n",
    "\n",
    "def vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y):\n",
    "    # Function that applies the LogPolar filter on an image, decreasing its resolution\n",
    "    # with the excentricity compared to its center.\n",
    "    # N_theta, N_orient, N_scale and N_phase define the filter shape\n",
    "    phi = np.zeros((N_theta, N_orient, N_scale, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    params= {'sf_0':.1, 'B_sf': lg.pe.B_sf, 'theta':np.pi* 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    phase = np.pi/4\n",
    "    edge = lg.normalize(lg.invert(lg.loggabor(N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "    \n",
    "    for i_theta in range(N_theta):\n",
    "        for i_orient in range(N_orient):\n",
    "            for i_scale in range(N_scale):\n",
    "                ecc =  .5**(N_scale - i_scale)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)\n",
    "                y = N_Y/2 + r * np.sin((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)            \n",
    "                for i_phase in range(N_phase):\n",
    "                    params= {'sf_0':sf_0, 'B_sf': lg.pe.B_sf, 'theta':i_theta*np.pi/N_theta, 'B_theta': np.pi/N_theta/2}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    phi[i_theta, i_orient, i_scale, i_phase, :] = lg.normalize(lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel()            \n",
    "    return phi\n",
    "\n",
    "def train_classifier(epoch):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, LABEL) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            #data, LABEL = data.cuda(), LABEL.cuda()           \n",
    "            LABEL = LABEL.cuda()           \n",
    "        INPUT = data.min() * np.ones((args.batch_size, 1, 128, 128))\n",
    "        #data, LABEL = Variable(data), Variable(LABEL)\n",
    "        LABEL = Variable(LABEL)\n",
    "\n",
    "        \n",
    "        for idx in range(args.batch_size):\n",
    "            i_offset, j_offset = minmax(int(np.random.randn()*0), 2), minmax(int(np.random.randn()*0), 2)\n",
    "            data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "            INPUT[idx, 0, :] = data_reshaped\n",
    "            \n",
    "        INPUT = torch.FloatTensor(INPUT)\n",
    "        #normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "        INPUT = Variable(INPUT)\n",
    "        if args.cuda: INPUT = INPUT.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        OUTPUT = model(INPUT)\n",
    "        \n",
    "        loss = F.nll_loss(OUTPUT, LABEL)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tElapsed time: {:.2f} mn'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0], (time.time()-t0)/60))\n",
    "\n",
    "def eval_classifier(epoch):\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss, correct = 0, 0\n",
    "    for batch_idx, (data, LABEL) in enumerate(eval_loader):\n",
    "        if args.cuda: \n",
    "            LABEL = LABEL.cuda() \n",
    "        LABEL = Variable(LABEL)\n",
    "        INPUT = np.zeros((args.batch_size, 1, 128, 128))\n",
    "        \n",
    "        for idx in range(args.batch_size):\n",
    "            i_offset, j_offset = minmax(int(np.random.randn()*0), 2), minmax(int(np.random.randn()*0), 2)\n",
    "            data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "            INPUT[idx,0,:] = data_reshaped\n",
    "            \n",
    "        INPUT = torch.FloatTensor(INPUT)\n",
    "        INPUT = Variable(INPUT, volatile=True)\n",
    "        if args.cuda: INPUT = INPUT.cuda()\n",
    "        \n",
    "        OUTPUT = model(INPUT)\n",
    "        eval_loss += F.nll_loss(OUTPUT, LABEL, size_average=False).data[0]\n",
    "        pred = OUTPUT.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(LABEL.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    eval_loss /= len(eval_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Elapsed time: {:.2f} mn'.format(eval_loss, \n",
    "                                                                                 correct, \n",
    "                                                                                 len(eval_loader.dataset),\n",
    "                                                                                 100. * correct / len(eval_loader.dataset),\n",
    "                                                                                 (time.time()-t0)/60))\n",
    "         \n",
    "def map_classifier():\n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    model.eval()\n",
    "    accuracy_map = np.zeros((128,128))\n",
    "\n",
    "    for batch_idx, (data, LABEL) in enumerate(eval_loader):\n",
    "        if args.cuda:\n",
    "            LABEL = LABEL.cuda()\n",
    "        LABEL = Variable(LABEL)\n",
    "\n",
    "        for i_offset in range(-11, 11, 1):\n",
    "            for j_offset in range(-11, 11, 1):        \n",
    "                INPUT = np.zeros((args.batch_size,1,128,128))\n",
    "                for idx in range(args.batch_size):\n",
    "                    data_reshaped = mnist_reshape_128(data[idx,0,:], i_offset, j_offset)\n",
    "                    INPUT[idx,0,:] =  data_reshaped\n",
    "\n",
    "                INPUT = torch.FloatTensor(INPUT)\n",
    "                INPUT = Variable(INPUT)\n",
    "                if args.cuda:\n",
    "                    INPUT = INPUT.cuda()\n",
    "\n",
    "                OUTPUT = model(INPUT)\n",
    "                pred = OUTPUT.data.max(1, keepdim=True)[1]\n",
    "                correct = pred.eq(LABEL.data.view_as(pred)).sum()\n",
    "                accuracy_map[i_offset+64-1][j_offset+64-1] += (correct / args.batch_size)\n",
    "\n",
    "                if time.time() - t1 > 30: \n",
    "                    print('i: {}, j: {}, elapsed time: {:.2f} mn'.format(i_offset, j_offset, (time.time()-t0)/60))\n",
    "                    t1 = time.time()\n",
    "        break\n",
    "                \n",
    "    return accuracy_map\n",
    "        \n",
    "            \n",
    "model = What()\n",
    "print('cuda:', args.cuda)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Defining the optimizer that'll train the network\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                      lr=args.lr,\n",
    "                      momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "%run Cert_detect.py --epoch=1 --lr=0.3\n",
    "path = 'Cert_detector.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.296373\tElapsed time: 0.00 mn\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.305507\tElapsed time: 0.03 mn\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.304607\tElapsed time: 0.07 mn\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.299665\tElapsed time: 0.10 mn\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.300058\tElapsed time: 0.13 mn\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.300825\tElapsed time: 0.16 mn\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.306840\tElapsed time: 0.19 mn\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.308253\tElapsed time: 0.23 mn\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.291221\tElapsed time: 0.26 mn\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.305447\tElapsed time: 0.29 mn\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.298825\tElapsed time: 0.32 mn\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.300486\tElapsed time: 0.35 mn\n",
      "\n",
      "Test set: Average loss: 2.3024, Accuracy: 982/10000 (10%), Elapsed time: 0.03 mn\n",
      "Training saved in Cert_detector.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(path):\n",
    "    print('Loading training values from', path)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "else:\n",
    "    print('Training...')\n",
    "    for epoch in range(1, args.epoch+1):\n",
    "        train_classifier(epoch)\n",
    "        eval_classifier(epoch)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Training saved in', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "\n",
      "Test set: Average loss: 2.3015, Accuracy: 1135/10000 (11%), Elapsed time: 1.481396 mn\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation...')\n",
    "for epoch in range(1, args.epoch+1):\n",
    "    eval_classifier(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy map construction...\n",
      "i: -10, j: 1, elapsed time: 0.51 mn\n",
      "i: -8, j: -8, elapsed time: 1.01 mn\n",
      "i: -7, j: 5, elapsed time: 1.51 mn\n",
      "i: -5, j: -4, elapsed time: 2.02 mn\n",
      "i: -4, j: 9, elapsed time: 2.52 mn\n",
      "i: -2, j: 0, elapsed time: 3.03 mn\n",
      "i: 0, j: -9, elapsed time: 3.53 mn\n",
      "i: 1, j: 4, elapsed time: 4.04 mn\n",
      "i: 3, j: -5, elapsed time: 4.54 mn\n",
      "i: 4, j: 8, elapsed time: 5.04 mn\n",
      "i: 6, j: -1, elapsed time: 5.55 mn\n",
      "i: 8, j: -10, elapsed time: 6.05 mn\n",
      "i: 9, j: 3, elapsed time: 6.56 mn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f95841a0710>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95ad32d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Accuracy map construction...')\n",
    "N_pix = 128//2\n",
    "fig, ax = plt.subplots(figsize=(13, 10.725))\n",
    "cmap = ax.pcolor(np.arange(-N_pix, N_pix), np.arange(-N_pix, N_pix), map_classifier())\n",
    "ax.axis('equal')\n",
    "fig.colorbar(cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
