{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/LP_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/LP_detect.py\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from LogGabor import LogGabor\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST detector')\n",
    "parser.add_argument('--batch_size', type=int, default=100, metavar='N',\n",
    "                   help='input batch size for training (default: 100)')\n",
    "parser.add_argument('--eval_batch_size', type=int, default=1000, metavar='N',\n",
    "                   help='input batch size for evaluation (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=2, metavar='N',\n",
    "                   help='number of training epochs (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                   help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                   help='SGM momentum for training (default: 0.5)')\n",
    "parser.add_argument('--not_cuda', action='store_true', default=True,\n",
    "                   help='Disables use of GPU during training (default: False)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                   help='random number seed (default: 1)')\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.not_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=True, \n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=args.eval_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 10, kernel_size=5)  # First layer        \n",
    "        self.conv2 = nn.Conv1d(10, 20, kernel_size=5) # Second layer\n",
    "        self.conv2_drop = nn.Dropout2d()              # Dropout layer\n",
    "        self.fc1 = nn.Linear(234, 50) # Input size, output size\n",
    "        self.fc2 = nn.Linear(50, 2)   # Input size, output size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # F.relu : Applies rectified linear unit function element-wise\n",
    "        # F.max_pool1d : Applies 1d max pooling over an input signal    \n",
    "        x = F.relu(F.max_pool1d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 234)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "print('cuda:', args.cuda)\n",
    "if args.cuda: model.cuda()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=args.lr, \n",
    "                      momentum=args.momentum)\n",
    "\n",
    "def mnist_reshape_128(x, i_off=0, j_off=0):\n",
    "    N_pix = 28\n",
    "    assert x.shape[2:4] == (N_pix,N_pix)\n",
    "    x_translate = np.zeros((N_pix*(128/N_pix), N_pix*(128/N_pix)))\n",
    "    x_translate[(N_pix+22+i_off):(2*N_pix+22+i_off), (N_pix+22+j_off):(2*N_pix+22+j_off)] = x[2,-1]\n",
    "    return x_translate\n",
    "\n",
    "def vectorization(N_theta,\n",
    "                  N_orient,\n",
    "                  N_scale,\n",
    "                  N_phase,\n",
    "                  N_X,\n",
    "                  N_Y):\n",
    "    phi = np.zeros((N_theta, N_orient, N_scale, N_phase, N_X*N_Y))\n",
    "\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    params= {'sf_0':.1, 'B_sf': lg.pe.B_sf, 'theta':np.pi* 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    phase = np.pi/4\n",
    "    edge = lg.normalize(lg.invert(lg.loggabor(N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "    \n",
    "    for i_theta in range(N_theta):\n",
    "        for i_orient in range(N_orient):\n",
    "            for i_scale in range(N_scale):\n",
    "                ecc =  .5**(N_scale - i_scale)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)\n",
    "                y = N_Y/2 + r * np.sin((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)            \n",
    "                for i_phase in range(N_phase):\n",
    "                    params= {'sf_0':sf_0, 'B_sf': lg.pe.B_sf, 'theta':i_theta*np.pi/N_theta, 'B_theta': np.pi/N_theta/2}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    phi[i_theta, i_orient, i_scale, i_phase, :] = lg.normalize(lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel()            \n",
    "    return phi\n",
    "\n",
    "def train(epoch):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    N_theta, N_orient, N_scale, N_phase, N_X, N_Y = 6, 8, 5, 2, 128, 128\n",
    "    phi = vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y)\n",
    "    phi_vector = phi.reshape((N_theta*N_orient*N_scale*N_phase, N_X*N_Y))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda: data = data.cuda()     \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        INPUT = np.zeros((data.shape[0], 1, 480))\n",
    "        coord = np.zeros((data.shape[0], 2))\n",
    "        \n",
    "        for idx in range(args.batch_size):\n",
    "            i_off, j_off = int(np.random.randn()*15), int(np.random.randn()*15)\n",
    "            coord[idx,:] = (i_off, j_off)\n",
    "        \n",
    "            t0_vect = time.time()\n",
    "            \n",
    "            data_reshaped = mnist_reshape_128(data, i_off, j_off)\n",
    "            \n",
    "            t1_vect = time.time() - t0_vect\n",
    "            \n",
    "            v = phi_vector @ np.ravel(data_reshaped) # 1D vector of size 480\n",
    "        \n",
    "            INPUT[idx,0,:] = v\n",
    "            \n",
    "            if idx == 0: \n",
    "                t2_vect = time.time() - t0_vect\n",
    "                print('Time to reshape one image (s):', t1_vect)\n",
    "                print('Time to reshape one image and process the vectorization (s):', t2_vect)\n",
    "        \n",
    "        t1 = time.time() - t0\n",
    "        print('Time to compute the whole dataset (s):', t1)\n",
    "        \n",
    "        INPUT = torch.FloatTensor(INPUT)        \n",
    "        INPUT = Variable(INPUT)\n",
    "        \n",
    "        coord = torch.FloatTensor(coord)\n",
    "        coord = Variable(coord)\n",
    "    \n",
    "        #optimizer.zero_grad()\n",
    "        OUTPUT = model(INPUT)\n",
    "        loss = F.mse_loss(OUTPUT, coord, size_average=True)\n",
    "        loss.backward() # computes the derivative\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, elapsed time: {}'.format(epoch, \n",
    "                                                                       batch_idx * len(data), \n",
    "                                                                       len(train_loader.dataset),\n",
    "                                                                       100. * batch_idx / len(train_loader), \n",
    "                                                                       loss.data[0],\n",
    "                                                                       time.time() - t0))\n",
    "\n",
    "def eval(test_loader=test_loader):\n",
    "    model.eval()\n",
    "    N_theta, N_orient, N_scale, N_phase, N_X, N_Y = 6, 8, 5, 2, 128, 128\n",
    "    phi = vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y)\n",
    "    phi_vector = phi.reshape((N_theta*N_orient*N_scale*N_phase, N_X*N_Y))\n",
    "    test_loss, correct = 0, 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda: data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        i_off, j_off = int(np.random.randn()*15), int(np.random.randn()*15)\n",
    "        coord = (i_off, j_off)\n",
    "        data_transform1 = mnist_reshape_128(data, i_off, j_off)\n",
    "        data_transform2 = phi_vector @ np.ravel(data_transform1)\n",
    "        output = model(data_transform2)\n",
    "        test_loss += F.nll_loss(output, coord, size_average=False).data[0]\n",
    "        pred = output.data[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, \n",
    "                                                                                 correct, \n",
    "                                                                                 len(test_loader.dataset),\n",
    "                                                                                 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: False\n"
     ]
    }
   ],
   "source": [
    "%run /tmp/LP_detect.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.523517370223999\n",
      "Time to reshape one image (s): 0.5237064361572266\n",
      "Time to reshape one image and process the vectorization (s): 0.5322926044464111\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5210058689117432\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5181078910827637\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5145468711853027\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5186178684234619\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.517402172088623\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5420002937316895\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5340526103973389\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5220708847045898\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5287230014801025\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5248591899871826\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5168700218200684\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5165798664093018\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.51749587059021\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5153591632843018\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5166852474212646\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5216319561004639\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5159265995025635\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5233273506164551\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5158126354217529\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5167262554168701\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.535109281539917\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5183579921722412\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5186913013458252\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5200438499450684\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5205957889556885\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5249416828155518\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5203959941864014\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5210199356079102\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.524120569229126\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5175948143005371\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5240325927734375\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.514336109161377\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5183320045471191\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5172500610351562\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5171844959259033\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5237865447998047\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5176668167114258\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5279152393341064\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5163154602050781\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.523195743560791\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5143880844116211\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5111773014068604\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5149414539337158\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5202693939208984\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5147743225097656\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5172109603881836\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5247542858123779\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5305383205413818\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5173897743225098\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5207290649414062\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.529322624206543\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5250546932220459\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5197045803070068\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5129156112670898\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5169029235839844\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5175445079803467\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5152881145477295\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.53824782371521\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5123963356018066\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5281610488891602\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5247964859008789\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5259795188903809\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5184791088104248\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5288386344909668\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.528331995010376\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5311064720153809\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.523892879486084\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5188019275665283\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5276041030883789\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5329463481903076\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.523991584777832\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5328402519226074\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.514387845993042\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5154132843017578\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5379650592803955\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5330648422241211\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5254733562469482\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5209810733795166\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5141751766204834\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5153293609619141\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to insert x into the 128,128 image: 0.5312604904174805\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5188491344451904\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5352973937988281\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5184972286224365\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5264334678649902\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5258040428161621\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5264742374420166\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5155274868011475\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5196168422698975\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5175120830535889\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5212833881378174\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.528144359588623\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5277116298675537\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5161161422729492\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5391378402709961\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.532341718673706\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5272059440612793\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5269691944122314\n",
      "(128, 128) torch.Size([100, 1, 28, 28])\n",
      "Time to insert x into the 128,128 image: 0.5184237957000732\n",
      "Time to compute the whole dataset (s): 53.12741279602051\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input and target have different number of elements: input[1000 x 2] has 2000 elements, while target[100 x 2] has 200 elements at /pytorch/torch/lib/THNN/generic/MSECriterion.c:13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2bf1561d91d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/LP_detect.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m#optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mOUTPUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# computes the derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \"\"\"\n\u001b[1;32m   1281\u001b[0m     return _pointwise_loss(lambda a, b: (a - b) ** 2, torch._C._nn.mse_loss,\n\u001b[0;32m-> 1282\u001b[0;31m                            input, target, size_average, reduce)\n\u001b[0m\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, size_average, reduce)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input and target have different number of elements: input[1000 x 2] has 2000 elements, while target[100 x 2] has 200 elements at /pytorch/torch/lib/THNN/generic/MSECriterion.c:13"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "path = \"MNIST_detector.pt\"\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    print('Loading file...')\n",
    "    model.load_state_dict(torch.load(path))\n",
    "else:\n",
    "    print('Training model...')\n",
    "    t0 = time.time()\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        train(epoch)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print('Done in', time.time()-t0, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
