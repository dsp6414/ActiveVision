{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script adapté de Waveimage-tensorflow-pow3-encoding_P3ver.ipynb afin d'y appliquer les méthodes de la librairie TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt # wavelets transforms library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Telecharger des exemples et leurs labels provenant de la base MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de modifier la taille et l'emplacement du stimulus dans l'image\n",
    "def mnist_reshape_128(x, i_offset = 0, j_offset = 0): # i,j : coordonnees du stimulus par rapport au centre de l'image\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28, 28)\n",
    "    image = np.append(np.zeros((128 + 2, 28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((128 + 2, 28)), axis = 0)\n",
    "    image = np.append(np.zeros((288, 128 + 2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((288, 128 + 2)), axis = 1)\n",
    "    return image[128 + 16 - 64 - i_offset : 128 + 16 + 64 - i_offset, 128 + 16 - 64 - j_offset : 128 + 16 + 64 - j_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fonction calculant le nombre d'ondelettes en fonction de l'echelle ? ; shape : taille image\n",
    "def calc_dim(shape, h, h_max):\n",
    "    assert 0 <= h < h_max # h : echelle de composition d'ondelette\n",
    "    if h == 0:\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - 1)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - 1)))\n",
    "    else :\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - h)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - h)))\n",
    "    return dim_i, dim_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveImage:\n",
    "\t\n",
    "\tdef __init__(self, image = None, shape = (32, 32)):\n",
    "\t\t\n",
    "\t\t# Attribut shape\n",
    "\t\tif image is not None:\n",
    "\t\t\t# Decomposition ondelettes\n",
    "\t\t\tcoeffs = pywt.wavedec2(image, 'haar') # haar correspond à une famille d'ondelettes\n",
    "\t\t\tself.__shape = image.shape\n",
    "\t\telse:\n",
    "\t\t\tself.__shape = shape\n",
    "\t\t\n",
    "\t\t# Attribut h_max : profondeur de l'image\n",
    "\t\tself.__h_max = min(int(math.log(self.__shape[0], 2)) + 1, \tint(math.log(self.__shape[1], 2)) + 1)\n",
    "\t\t\t\n",
    "\t\t# Attribut data : L'attribut data contient les vecteurs en position [h][u] (dictionnaire)\n",
    "\t\tif image is not None:\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h].shape\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h][0].shape\n",
    "\t\t\t\tfor i in range(i_max):\n",
    "\t\t\t\t\tfor j in range(j_max):\n",
    "\t\t\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][i][j]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][0][i][j] # k : num ondelette ?\n",
    "\t\t\t\t\t\t\tfor k in range(1,len(coeffs[h])):\n",
    "\t\t\t\t\t\t\t\tdata = np.append(data, coeffs[h][k][i][j])\t\n",
    "\t\t\t\t\t\tself.__data[h][(i, j)] = data\t\t\t\t\n",
    "\t\telse: # image is None\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\t\t\n",
    "\t\t\n",
    "\tdef get_data(self):\n",
    "\t\treturn self.__data\n",
    "\t\n",
    "\tdef get_shape(self):\n",
    "\t\treturn self.__data\n",
    "\t\t\t\t\n",
    "\tdef set_data(self, h, u, v):\n",
    "\t\tassert 0 <= h < self.__h_max\n",
    "\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\tassert 0 <= u[0] < dim_i\n",
    "\t\tassert 0 <= u[1] < dim_j\n",
    "\t\tif h == 0 :\n",
    "\t\t\tself.__data[h][u] = v\n",
    "\t\telse:\n",
    "\t\t\tself.__data[h][u] = np.copy(v)\n",
    "\t\t\n",
    "\tdef get_h_max(self):\n",
    "\t\treturn self.__h_max\n",
    "\t\t\n",
    "\tdef get_image(self): # etape decodage pour retrouver image\n",
    "\t\tcoeffs = []\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\t\tif h == 0:\n",
    "\t\t\t\tcoeffs_h = np.zeros((dim_i, dim_j))\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tcoeffs_h[u[0],u[1]] = self.__data[h][u]\n",
    "\t\t\telse:\n",
    "\t\t\t\tcoeffs_h = [np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j))]\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tfor k in range(3):\n",
    "\t\t\t\t\t\tcoeffs_h[k][u[0],u[1]] = self.__data[h][u][k]\n",
    "\t\t\tcoeffs += [coeffs_h]\n",
    "\t\treturn pywt.waverec2(coeffs, 'haar')\n",
    "\t\t\n",
    "\tdef add_coeffs(self, waveImage, u, h_ref = 0): # copie certains niveaux de l'arbre d'ondelettes\n",
    "\t\t# Niveau 0\n",
    "\t\th_opp = self.__h_max - 1\n",
    "\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\tu_0 = (i,j)\n",
    "\t\tif self.__data[0] == {}:\n",
    "\t\t\tself.__data[0][u_0] = waveImage.get_data()[0][u_0]\n",
    "\t\telse:\n",
    "\t\t\tv_test = self.__data[0][u_0]\n",
    "\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\tself.__data[0][u_0] = waveImage.getData()[0][u_0]\n",
    "\t\t# Niveaux 1 et +\n",
    "\t\tfor h in range(1, h_ref) :\n",
    "\t\t\th_opp = self.__h_max - h\n",
    "\t\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\t\tif (i,j) in self.__data[h]:\n",
    "\t\t\t\tv_test = self.__data[h][(i,j)]\n",
    "\t\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\t\telse: \n",
    "\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\n",
    "\tdef copy(self): # copie complete\n",
    "\t\tself_shape = self.__shape \n",
    "\t\tself_copy = WaveImage(shape = self_shape)\n",
    "\t\tfor h in range(self.__h_max) :\n",
    "\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\tself_copy.set_data(h, u, self.__data[h][u])\n",
    "\t\treturn self_copy\t\n",
    "\t\t\n",
    "\tdef __str__(self): # affiche contenu objet\n",
    "\t\th_max = len(self.__data)\n",
    "\t\ts = 'h_max :' + str(self.__h_max) + '\\n'\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\ts += '***' + str(h) + '***\\n'\n",
    "\t\t\ts += str(self.__data[h]) + '\\n'\n",
    "\t\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genere un dictionnaire de tenseurs indexes par la profondeur dans l'arbre des coefficients d'ondelettes \n",
    "def generate_tensor_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max()\n",
    "    data = w1.get_data()\n",
    "    tensor_data = {}\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            tensor_data[0] = data[k][(0, 0)]\n",
    "        elif k == 1:\n",
    "            tensor_data[1] = np.array(data[k][(0, 0)])    \n",
    "        else:\n",
    "            tensor_data[k] = np.zeros((2, 2, 3))\n",
    "            for u in data[k]:           \n",
    "                u_offset = 64 // (2**(h_max - k)) - 1\n",
    "                tensor_data[k][u[0] - u_offset, u[1] - u_offset, :] = np.array(data[k][u])\n",
    "    return tensor_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    # retourne un vecteur contenant les coefficients utilisés de l'image w1 générée à partir d'un point de fixation\n",
    "    # central avec la cible en position i_offset, j_offset\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max() # h = 7\n",
    "    data = w1.get_data()\n",
    "    vector_data = np.array([])\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            vector_data = np.append(vector_data, [data[k][(0, 0)]])\n",
    "        elif k == 1:\n",
    "            vector_data = np.append(vector_data, data[k][(0, 0)])  \n",
    "        else:\n",
    "            for u in data[k]:           \n",
    "                 vector_data = np.append(vector_data, data[k][u])\n",
    "    return vector_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(value,   #valeur a delimiter\n",
    "           border): #limite min/max a ne pas depasser \n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégration d'un régression linéaire via TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # taille de l'échantillon\n",
    "iterations = 1000 # nombre d'itérations à réaliser dans l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4stt7pgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4stt7pgs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea3ec2a898>, '_is_chief': True, '_master': '', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_task_id': 0, '_model_dir': '/tmp/tmp4stt7pgs', '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_tf_random_seed': None, '_session_config': None, '_save_summary_steps': 100, '_task_type': 'worker', '_keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fea3ec2a898>, '_is_chief': True, '_master': '', '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_task_id': 0, '_model_dir': '/tmp/tmp4stt7pgs', '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_tf_random_seed': None, '_session_config': None, '_save_summary_steps': 100, '_task_type': 'worker', '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# Définir la liste de features\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[76])]\n",
    "\n",
    "# Définir le type d'estimateur utilisé\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, label_dimension=2)\n",
    "\n",
    "### Définition des jeux de données\n",
    "# Récuperation des données pour la phase d'apprentissage\n",
    "batch = mnist.train.next_batch(batch_size)\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnées réelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_train += [(v)]\n",
    "    y_train += [(i_offset, j_offset)]\n",
    "\n",
    "# Récupération des données pour la phase d'évaluation\n",
    "batch = mnist.test.next_batch(batch_size)\n",
    "x_eval, y_eval = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnees reelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_eval += [(v)]\n",
    "    y_eval += [(i_offset, j_offset)]\n",
    "    \n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\" : np.array(x_train)},\n",
    "                                              np.array(y_train),\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_epochs=None,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp4stt7pgs/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp4stt7pgs/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 445594.0, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 445594.0, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 153.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 153.197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 129573.0, step = 101 (0.655 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 129573.0, step = 101 (0.655 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 190.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 190.401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 112251.0, step = 201 (0.529 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 112251.0, step = 201 (0.529 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 175.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 175.719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 103453.0, step = 301 (0.565 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 103453.0, step = 301 (0.565 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 191.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 191.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 95724.2, step = 401 (0.528 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 95724.2, step = 401 (0.528 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 198.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 198.332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 98571.6, step = 501 (0.504 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 98571.6, step = 501 (0.504 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 209.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 209.585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88216.6, step = 601 (0.475 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88216.6, step = 601 (0.475 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 81455.8, step = 701 (0.493 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 81455.8, step = 701 (0.493 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 74642.2, step = 801 (0.710 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 74642.2, step = 801 (0.710 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 186.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 186.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 79914.1, step = 901 (0.560 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 79914.1, step = 901 (0.560 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp4stt7pgs/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp4stt7pgs/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74179.7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74179.7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fea3ec2a828>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancement de l'entrainement\n",
    "estimator.train(input_fn=input_fn, steps=iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics : {'average_loss': 36.765797, 'global_step': 1000, 'loss': 73531.594}\n",
      "eval metrics : {'average_loss': 39.080402, 'global_step': 1000, 'loss': 78160.805}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation de l'efficacité du modèle\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_train)},\n",
    "                                             np.array(y_train),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_eval)},\n",
    "                                             np.array(y_eval),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics : %r\"% train_metrics)\n",
    "print(\"eval metrics : %r\"% eval_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
