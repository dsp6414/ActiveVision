{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script adapté de Waveimage-tensorflow-pow3-encoding_P3ver.ipynb afin d'y appliquer les méthodes de la librairie TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraires et fonctions nécessaires au fonctionnement du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt # wavelets transforms library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Telecharger des exemples et leurs labels provenant de la base MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de modifier la taille et l'emplacement du stimulus dans l'image\n",
    "def mnist_reshape_128(x, i_offset = 0, j_offset = 0): # i,j : coordonnees du stimulus par rapport au centre de l'image\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28, 28)\n",
    "    image = np.append(np.zeros((128 + 2, 28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((128 + 2, 28)), axis = 0)\n",
    "    image = np.append(np.zeros((288, 128 + 2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((288, 128 + 2)), axis = 1)\n",
    "    return image[128 + 16 - 64 - i_offset : 128 + 16 + 64 - i_offset, 128 + 16 - 64 - j_offset : 128 + 16 + 64 - j_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fonction calculant le nombre d'ondelettes en fonction de l'echelle ? ; shape : taille image\n",
    "def calc_dim(shape, h, h_max):\n",
    "    assert 0 <= h < h_max # h : echelle de composition d'ondelette\n",
    "    if h == 0:\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - 1)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - 1)))\n",
    "    else :\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - h)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - h)))\n",
    "    return dim_i, dim_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveImage:\n",
    "\t\n",
    "\tdef __init__(self, image = None, shape = (32, 32)):\n",
    "\t\t\n",
    "\t\t# Attribut shape\n",
    "\t\tif image is not None:\n",
    "\t\t\t# Decomposition ondelettes\n",
    "\t\t\tcoeffs = pywt.wavedec2(image, 'haar') # haar correspond à une famille d'ondelettes\n",
    "\t\t\tself.__shape = image.shape\n",
    "\t\telse:\n",
    "\t\t\tself.__shape = shape\n",
    "\t\t\n",
    "\t\t# Attribut h_max : profondeur de l'image\n",
    "\t\tself.__h_max = min(int(math.log(self.__shape[0], 2)) + 1, \tint(math.log(self.__shape[1], 2)) + 1)\n",
    "\t\t\t\n",
    "\t\t# Attribut data : L'attribut data contient les vecteurs en position [h][u] (dictionnaire)\n",
    "\t\tif image is not None:\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h].shape\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h][0].shape\n",
    "\t\t\t\tfor i in range(i_max):\n",
    "\t\t\t\t\tfor j in range(j_max):\n",
    "\t\t\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][i][j]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][0][i][j] # k : num ondelette ?\n",
    "\t\t\t\t\t\t\tfor k in range(1,len(coeffs[h])):\n",
    "\t\t\t\t\t\t\t\tdata = np.append(data, coeffs[h][k][i][j])\t\n",
    "\t\t\t\t\t\tself.__data[h][(i, j)] = data\t\t\t\t\n",
    "\t\telse: # image is None\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\t\t\n",
    "\t\t\n",
    "\tdef get_data(self):\n",
    "\t\treturn self.__data\n",
    "\t\n",
    "\tdef get_shape(self):\n",
    "\t\treturn self.__data\n",
    "\t\t\t\t\n",
    "\tdef set_data(self, h, u, v):\n",
    "\t\tassert 0 <= h < self.__h_max\n",
    "\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\tassert 0 <= u[0] < dim_i\n",
    "\t\tassert 0 <= u[1] < dim_j\n",
    "\t\tif h == 0 :\n",
    "\t\t\tself.__data[h][u] = v\n",
    "\t\telse:\n",
    "\t\t\tself.__data[h][u] = np.copy(v)\n",
    "\t\t\n",
    "\tdef get_h_max(self):\n",
    "\t\treturn self.__h_max\n",
    "\t\t\n",
    "\tdef get_image(self): # etape decodage pour retrouver image\n",
    "\t\tcoeffs = []\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\t\tif h == 0:\n",
    "\t\t\t\tcoeffs_h = np.zeros((dim_i, dim_j))\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tcoeffs_h[u[0],u[1]] = self.__data[h][u]\n",
    "\t\t\telse:\n",
    "\t\t\t\tcoeffs_h = [np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j))]\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tfor k in range(3):\n",
    "\t\t\t\t\t\tcoeffs_h[k][u[0],u[1]] = self.__data[h][u][k]\n",
    "\t\t\tcoeffs += [coeffs_h]\n",
    "\t\treturn pywt.waverec2(coeffs, 'haar')\n",
    "\t\t\n",
    "\tdef add_coeffs(self, waveImage, u, h_ref = 0): # copie certains niveaux de l'arbre d'ondelettes\n",
    "\t\t# Niveau 0\n",
    "\t\th_opp = self.__h_max - 1\n",
    "\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\tu_0 = (i,j)\n",
    "\t\tif self.__data[0] == {}:\n",
    "\t\t\tself.__data[0][u_0] = waveImage.get_data()[0][u_0]\n",
    "\t\telse:\n",
    "\t\t\tv_test = self.__data[0][u_0]\n",
    "\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\tself.__data[0][u_0] = waveImage.getData()[0][u_0]\n",
    "\t\t# Niveaux 1 et +\n",
    "\t\tfor h in range(1, h_ref) :\n",
    "\t\t\th_opp = self.__h_max - h\n",
    "\t\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\t\tif (i,j) in self.__data[h]:\n",
    "\t\t\t\tv_test = self.__data[h][(i,j)]\n",
    "\t\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\t\telse: \n",
    "\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\n",
    "\tdef copy(self): # copie complete\n",
    "\t\tself_shape = self.__shape \n",
    "\t\tself_copy = WaveImage(shape = self_shape)\n",
    "\t\tfor h in range(self.__h_max) :\n",
    "\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\tself_copy.set_data(h, u, self.__data[h][u])\n",
    "\t\treturn self_copy\t\n",
    "\t\t\n",
    "\tdef __str__(self): # affiche contenu objet\n",
    "\t\th_max = len(self.__data)\n",
    "\t\ts = 'h_max :' + str(self.__h_max) + '\\n'\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\ts += '***' + str(h) + '***\\n'\n",
    "\t\t\ts += str(self.__data[h]) + '\\n'\n",
    "\t\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genere un dictionnaire de tenseurs indexes par la profondeur dans l'arbre des coefficients d'ondelettes \n",
    "def generate_tensor_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max()\n",
    "    data = w1.get_data()\n",
    "    tensor_data = {}\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            tensor_data[0] = data[k][(0, 0)]\n",
    "        elif k == 1:\n",
    "            tensor_data[1] = np.array(data[k][(0, 0)])    \n",
    "        else:\n",
    "            tensor_data[k] = np.zeros((2, 2, 3))\n",
    "            for u in data[k]:           \n",
    "                u_offset = 64 // (2**(h_max - k)) - 1\n",
    "                tensor_data[k][u[0] - u_offset, u[1] - u_offset, :] = np.array(data[k][u])\n",
    "    return tensor_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    # retourne un vecteur contenant les coefficients utilisés de l'image w1 générée à partir d'un point de fixation\n",
    "    # central avec la cible en position i_offset, j_offset\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max() # h = 7\n",
    "    data = w1.get_data()\n",
    "    vector_data = np.array([])\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            vector_data = np.append(vector_data, [data[k][(0, 0)]])\n",
    "        elif k == 1:\n",
    "            vector_data = np.append(vector_data, data[k][(0, 0)])  \n",
    "        else:\n",
    "            for u in data[k]:           \n",
    "                 vector_data = np.append(vector_data, data[k][u])\n",
    "    return vector_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(value,   #valeur a delimiter\n",
    "           border): #limite min/max a ne pas depasser \n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégration d'un régression linéaire via TF - Version haut-niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # taille de l'échantillon\n",
    "iterations = 1000 # nombre d'itérations à réaliser dans l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnxkvwf6x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnxkvwf6x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc985f355f8>, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmpnxkvwf6x', '_task_id': 0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc985f355f8>, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmpnxkvwf6x', '_task_id': 0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Définir la liste de features\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[76])]\n",
    "\n",
    "# Définir le type d'estimateur utilisé\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, label_dimension=2)\n",
    "\n",
    "### Définition des jeux de données\n",
    "# Récuperation des données pour la phase d'apprentissage\n",
    "\n",
    "batch = mnist.train.next_batch(batch_size)\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnées réelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_train += [(v)]\n",
    "    y_train += [(i_offset, j_offset)]\n",
    "\n",
    "# Récupération des données pour la phase d'évaluation\n",
    "batch = mnist.test.next_batch(batch_size)\n",
    "x_eval, y_eval = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnees reelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_eval += [(v)]\n",
    "    y_eval += [(i_offset, j_offset)]\n",
    "    \n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\" : np.array(x_train)},\n",
    "                                              np.array(y_train),\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_epochs=None,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 404572.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 404572.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 152.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 152.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 107546.0 (0.662 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 107546.0 (0.662 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 167.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 167.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 201, loss = 107946.0 (0.594 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 201, loss = 107946.0 (0.594 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 173.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 173.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 301, loss = 89887.0 (0.581 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 301, loss = 89887.0 (0.581 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 401, loss = 100763.0 (0.506 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 401, loss = 100763.0 (0.506 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 165.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 165.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 501, loss = 77809.1 (0.605 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 501, loss = 77809.1 (0.605 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 146.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 146.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 601, loss = 83685.1 (0.683 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 601, loss = 83685.1 (0.683 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 701, loss = 80924.2 (0.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 701, loss = 80924.2 (0.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 801, loss = 74483.8 (0.496 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 801, loss = 74483.8 (0.496 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 901, loss = 79866.8 (0.507 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 901, loss = 79866.8 (0.507 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74304.1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74304.1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fc985f31b70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancement de l'entrainement\n",
    "estimator.train(input_fn=input_fn, steps=iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['global_step', 'linear/linear_model/bias_weights', 'linear/linear_model/bias_weights/part_0/Ftrl', 'linear/linear_model/bias_weights/part_0/Ftrl_1', 'linear/linear_model/x/weights', 'linear/linear_model/x/weights/part_0/Ftrl', 'linear/linear_model/x/weights/part_0/Ftrl_1']\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les noms des variables comprises dans le modèle\n",
    "print(estimator.get_variable_names())\n",
    "# Récupérer la variable Arg1 comprise dans le modèle\n",
    "weights = estimator.get_variable_value('linear/linear_model/x/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics : {'average_loss': 36.765797, 'global_step': 1000, 'loss': 73531.594}\n",
      "eval metrics : {'average_loss': 39.080402, 'global_step': 1000, 'loss': 78160.805}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation de l'efficacité du modèle\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_train)},\n",
    "                                             np.array(y_train),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_eval)},\n",
    "                                             np.array(y_eval),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics : %r\"% train_metrics)\n",
    "print(\"eval metrics : %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégration d'une régression linéaire via TF - Version bas-niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-51c78d402cd8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-51c78d402cd8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    tensorboard --logdir=Documents/Notebooks/\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
