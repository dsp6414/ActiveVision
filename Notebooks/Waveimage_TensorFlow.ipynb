{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script adapté de Waveimage-tensorflow-pow3-encoding_P3ver.ipynb afin d'y appliquer les méthodes de la librairie TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraires et fonctions nécessaires au fonctionnement du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt # wavelets transforms library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Telecharger des exemples et leurs labels provenant de la base MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de modifier la taille et l'emplacement du stimulus dans l'image\n",
    "def mnist_reshape_128(x, i_offset = 0, j_offset = 0): # i,j : coordonnees du stimulus par rapport au centre de l'image\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28, 28)\n",
    "    image = np.append(np.zeros((128 + 2, 28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((128 + 2, 28)), axis = 0)\n",
    "    image = np.append(np.zeros((288, 128 + 2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((288, 128 + 2)), axis = 1)\n",
    "    return image[128 + 16 - 64 - i_offset : 128 + 16 + 64 - i_offset, 128 + 16 - 64 - j_offset : 128 + 16 + 64 - j_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fonction calculant le nombre d'ondelettes en fonction de l'echelle ? ; shape : taille image\n",
    "def calc_dim(shape, h, h_max):\n",
    "    assert 0 <= h < h_max # h : echelle de composition d'ondelette\n",
    "    if h == 0:\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - 1)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - 1)))\n",
    "    else :\n",
    "        dim_i = int(math.ceil(shape[0] * 1. // 2**(h_max - h)))\n",
    "        dim_j = int(math.ceil(shape[1] * 1. // 2**(h_max - h)))\n",
    "    return dim_i, dim_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveImage:\n",
    "\t\n",
    "\tdef __init__(self, image = None, shape = (32, 32)):\n",
    "\t\t\n",
    "\t\t# Attribut shape\n",
    "\t\tif image is not None:\n",
    "\t\t\t# Decomposition ondelettes\n",
    "\t\t\tcoeffs = pywt.wavedec2(image, 'haar') # haar correspond à une famille d'ondelettes\n",
    "\t\t\tself.__shape = image.shape\n",
    "\t\telse:\n",
    "\t\t\tself.__shape = shape\n",
    "\t\t\n",
    "\t\t# Attribut h_max : profondeur de l'image\n",
    "\t\tself.__h_max = min(int(math.log(self.__shape[0], 2)) + 1, \tint(math.log(self.__shape[1], 2)) + 1)\n",
    "\t\t\t\n",
    "\t\t# Attribut data : L'attribut data contient les vecteurs en position [h][u] (dictionnaire)\n",
    "\t\tif image is not None:\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h].shape\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t(i_max, j_max) = coeffs[h][0].shape\n",
    "\t\t\t\tfor i in range(i_max):\n",
    "\t\t\t\t\tfor j in range(j_max):\n",
    "\t\t\t\t\t\tif h == 0:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][i][j]\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tdata = coeffs[h][0][i][j] # k : num ondelette ?\n",
    "\t\t\t\t\t\t\tfor k in range(1,len(coeffs[h])):\n",
    "\t\t\t\t\t\t\t\tdata = np.append(data, coeffs[h][k][i][j])\t\n",
    "\t\t\t\t\t\tself.__data[h][(i, j)] = data\t\t\t\t\n",
    "\t\telse: # image is None\n",
    "\t\t\tself.__data = {}\n",
    "\t\t\tfor h in range(self.__h_max):\n",
    "\t\t\t\tself.__data[h] = {}\n",
    "\t\t\t\t\t\n",
    "\t\t\n",
    "\tdef get_data(self):\n",
    "\t\treturn self.__data\n",
    "\t\n",
    "\tdef get_shape(self):\n",
    "\t\treturn self.__data\n",
    "\t\t\t\t\n",
    "\tdef set_data(self, h, u, v):\n",
    "\t\tassert 0 <= h < self.__h_max\n",
    "\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\tassert 0 <= u[0] < dim_i\n",
    "\t\tassert 0 <= u[1] < dim_j\n",
    "\t\tif h == 0 :\n",
    "\t\t\tself.__data[h][u] = v\n",
    "\t\telse:\n",
    "\t\t\tself.__data[h][u] = np.copy(v)\n",
    "\t\t\n",
    "\tdef get_h_max(self):\n",
    "\t\treturn self.__h_max\n",
    "\t\t\n",
    "\tdef get_image(self): # etape decodage pour retrouver image\n",
    "\t\tcoeffs = []\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\tdim_i, dim_j = calc_dim(self.__shape, h, self.__h_max)\n",
    "\t\t\tif h == 0:\n",
    "\t\t\t\tcoeffs_h = np.zeros((dim_i, dim_j))\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tcoeffs_h[u[0],u[1]] = self.__data[h][u]\n",
    "\t\t\telse:\n",
    "\t\t\t\tcoeffs_h = [np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j)), np.zeros((dim_i, dim_j))]\n",
    "\t\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\t\tfor k in range(3):\n",
    "\t\t\t\t\t\tcoeffs_h[k][u[0],u[1]] = self.__data[h][u][k]\n",
    "\t\t\tcoeffs += [coeffs_h]\n",
    "\t\treturn pywt.waverec2(coeffs, 'haar')\n",
    "\t\t\n",
    "\tdef add_coeffs(self, waveImage, u, h_ref = 0): # copie certains niveaux de l'arbre d'ondelettes\n",
    "\t\t# Niveau 0\n",
    "\t\th_opp = self.__h_max - 1\n",
    "\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\tu_0 = (i,j)\n",
    "\t\tif self.__data[0] == {}:\n",
    "\t\t\tself.__data[0][u_0] = waveImage.get_data()[0][u_0]\n",
    "\t\telse:\n",
    "\t\t\tv_test = self.__data[0][u_0]\n",
    "\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\tself.__data[0][u_0] = waveImage.getData()[0][u_0]\n",
    "\t\t# Niveaux 1 et +\n",
    "\t\tfor h in range(1, h_ref) :\n",
    "\t\t\th_opp = self.__h_max - h\n",
    "\t\t\ti = int(u[0] // 2**h_opp) \n",
    "\t\t\tj = int(u[1] // 2**h_opp)\n",
    "\t\t\tif (i,j) in self.__data[h]:\n",
    "\t\t\t\tv_test = self.__data[h][(i,j)]\n",
    "\t\t\t\tif np.linalg.norm(v_test) < 1e-16:\n",
    "\t\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\t\telse: \n",
    "\t\t\t\tself.__data[h][(i,j)] = np.copy(waveImage.get_data()[h][(i,j)])\n",
    "\t\n",
    "\tdef copy(self): # copie complete\n",
    "\t\tself_shape = self.__shape \n",
    "\t\tself_copy = WaveImage(shape = self_shape)\n",
    "\t\tfor h in range(self.__h_max) :\n",
    "\t\t\tfor u in self.__data[h]:\n",
    "\t\t\t\tself_copy.set_data(h, u, self.__data[h][u])\n",
    "\t\treturn self_copy\t\n",
    "\t\t\n",
    "\tdef __str__(self): # affiche contenu objet\n",
    "\t\th_max = len(self.__data)\n",
    "\t\ts = 'h_max :' + str(self.__h_max) + '\\n'\n",
    "\t\tfor h in range(self.__h_max):\n",
    "\t\t\ts += '***' + str(h) + '***\\n'\n",
    "\t\t\ts += str(self.__data[h]) + '\\n'\n",
    "\t\treturn s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genere un dictionnaire de tenseurs indexes par la profondeur dans l'arbre des coefficients d'ondelettes \n",
    "def generate_tensor_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max()\n",
    "    data = w1.get_data()\n",
    "    tensor_data = {}\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            tensor_data[0] = data[k][(0, 0)]\n",
    "        elif k == 1:\n",
    "            tensor_data[1] = np.array(data[k][(0, 0)])    \n",
    "        else:\n",
    "            tensor_data[k] = np.zeros((2, 2, 3))\n",
    "            for u in data[k]:           \n",
    "                u_offset = 64 // (2**(h_max - k)) - 1\n",
    "                tensor_data[k][u[0] - u_offset, u[1] - u_offset, :] = np.array(data[k][u])\n",
    "    return tensor_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector_data_with_offset_from_x(x, i_offset, j_offset):\n",
    "    # retourne un vecteur contenant les coefficients utilisés de l'image w1 générée à partir d'un point de fixation\n",
    "    # central avec la cible en position i_offset, j_offset\n",
    "    w1 = WaveImage(shape = (128, 128))\n",
    "    w2 = WaveImage(image = mnist_reshape_128(x, i_offset = i_offset, j_offset = j_offset))\n",
    "    w1.add_coeffs(w2, u = (63, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (63, 65), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 63), h_ref = w2.get_h_max())\n",
    "    w1.add_coeffs(w2, u = (65, 65), h_ref = w2.get_h_max())\n",
    "    h_max = w1.get_h_max() # h = 7\n",
    "    data = w1.get_data()\n",
    "    vector_data = np.array([])\n",
    "    for k in data :\n",
    "        if k == 0:\n",
    "            vector_data = np.append(vector_data, [data[k][(0, 0)]])\n",
    "        elif k == 1:\n",
    "            vector_data = np.append(vector_data, data[k][(0, 0)])  \n",
    "        else:\n",
    "            for u in data[k]:           \n",
    "                 vector_data = np.append(vector_data, data[k][u])\n",
    "    return vector_data, w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(value,   #valeur a delimiter\n",
    "           border): #limite min/max a ne pas depasser \n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégration d'un régression linéaire via TF - Version haut-niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000 # taille de l'échantillon\n",
    "iterations = 1000  # nombre d'itérations à réaliser dans l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnxkvwf6x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnxkvwf6x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc985f355f8>, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmpnxkvwf6x', '_task_id': 0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_service': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc985f355f8>, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmpnxkvwf6x', '_task_id': 0, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Définir la liste de features\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[76])]\n",
    "\n",
    "# Définir le type d'estimateur utilisé\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, label_dimension=2)\n",
    "\n",
    "### Définition des jeux de données\n",
    "# Récuperation des données pour la phase d'apprentissage\n",
    "\n",
    "batch = mnist.train.next_batch(batch_size)\n",
    "x_train, y_train = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnées réelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_train += [(v)]\n",
    "    y_train += [(i_offset, j_offset)]\n",
    "\n",
    "# Récupération des données pour la phase d'évaluation\n",
    "batch = mnist.test.next_batch(batch_size)\n",
    "x_eval, y_eval = [], []\n",
    "\n",
    "for x in batch[0]:\n",
    "    # i, j correspondent aux coordonnees reelles de la cible, comprises dans l'intervalle (-40,40)\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    x_eval += [(v)]\n",
    "    y_eval += [(i_offset, j_offset)]\n",
    "    \n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\" : np.array(x_train)},\n",
    "                                              np.array(y_train),\n",
    "                                              batch_size=batch_size,\n",
    "                                              num_epochs=None,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 404572.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 404572.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 152.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 152.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 107546.0 (0.662 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 107546.0 (0.662 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 167.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 167.654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 201, loss = 107946.0 (0.594 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 201, loss = 107946.0 (0.594 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 173.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 173.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 301, loss = 89887.0 (0.581 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 301, loss = 89887.0 (0.581 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 401, loss = 100763.0 (0.506 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 401, loss = 100763.0 (0.506 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 165.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 165.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 501, loss = 77809.1 (0.605 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 501, loss = 77809.1 (0.605 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 146.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 146.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 601, loss = 83685.1 (0.683 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 601, loss = 83685.1 (0.683 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 140.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 701, loss = 80924.2 (0.709 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 701, loss = 80924.2 (0.709 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 203.602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 801, loss = 74483.8 (0.496 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 801, loss = 74483.8 (0.496 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 196.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 901, loss = 79866.8 (0.507 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 901, loss = 79866.8 (0.507 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpnxkvwf6x/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74304.1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 74304.1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fc985f31b70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lancement de l'entrainement\n",
    "estimator.train(input_fn=input_fn, steps=iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['global_step', 'linear/linear_model/bias_weights', 'linear/linear_model/bias_weights/part_0/Ftrl', 'linear/linear_model/bias_weights/part_0/Ftrl_1', 'linear/linear_model/x/weights', 'linear/linear_model/x/weights/part_0/Ftrl', 'linear/linear_model/x/weights/part_0/Ftrl_1']\n"
     ]
    }
   ],
   "source": [
    "# Récupérer les noms des variables comprises dans le modèle\n",
    "print(estimator.get_variable_names())\n",
    "# Récupérer la variable Arg1 comprise dans le modèle\n",
    "weights = estimator.get_variable_value('linear/linear_model/x/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 36.7658, global_step = 1000, loss = 73531.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-01-19-15:23:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmp4stt7pgs/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-01-19-15:23:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 39.0804, global_step = 1000, loss = 78160.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics : {'average_loss': 36.765797, 'global_step': 1000, 'loss': 73531.594}\n",
      "eval metrics : {'average_loss': 39.080402, 'global_step': 1000, 'loss': 78160.805}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation de l'efficacité du modèle\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_train)},\n",
    "                                             np.array(y_train),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": np.array(x_eval)},\n",
    "                                             np.array(y_eval),\n",
    "                                             batch_size=batch_size,\n",
    "                                             num_epochs=iterations,\n",
    "                                             shuffle=False)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics : %r\"% train_metrics)\n",
    "print(\"eval metrics : %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intégration d'une régression linéaire via TF - Version bas-niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser les paramètres\n",
    "batch_size = 3\n",
    "iterations = 3\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 2 for 'Slice_9' (op: 'Slice') with input shapes: [3,76], ?, [1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 2 for 'Slice_9' (op: 'Slice') with input shapes: [3,76], ?, [1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-ff71460ca171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxslice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx_train_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dbg1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dgb2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m   \"\"\"\n\u001b[0;32m--> 590\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   4633\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4634\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4635\u001b[0;31m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[0m\u001b[1;32m   4636\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4637\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 2 for 'Slice_9' (op: 'Slice') with input shapes: [3,76], ?, [1]."
     ]
    }
   ],
   "source": [
    "# Créer les placeholders et variables\n",
    "x_train = tf.placeholder(tf.float32, shape=[batch_size, 76]) # input (vector_data)\n",
    "y_train = tf.placeholder(tf.float32, shape=[batch_size, 2])  # labels (coordonnées)\n",
    "weights = tf.Variable(tf.zeros([2,76]))\n",
    "\n",
    "xslice = tf.placeholder(tf.int32)\n",
    "x_train_slice = tf.slice(x_train, xslice, size=[1])\n",
    "print('dbg1', x_train) ; print('dgb2', x_train_slice)\n",
    "\n",
    "# Initialiser les variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Récupération des données\n",
    "batch = mnist.test.next_batch(batch_size)\n",
    "num_x = 0\n",
    "for x in batch[0]:\n",
    "    i_offset, j_offset = minmax(int(np.random.randn() * 15), 40), minmax(int(np.random.randn() * 15), 40)  \n",
    "    v, w = generate_vector_data_with_offset_from_x(x, i_offset, j_offset) # v: vector, utilise comme x\n",
    "    #sess.run(x_train, feed_dict={x_train[:,num_x]: v}) ; print('dbg3', x_train)\n",
    "    sess.run(x_train_slice, feed_dict={x: v})\n",
    "    num_x += 1\n",
    "    \n",
    "# Calcul hypothèse !!pas encore fonctionnel!!\n",
    "hypo = tf.matmul(weights, x_train)\n",
    "\n",
    "# Calcul coût\n",
    "cost = (1/(2*batch_size))*tf.reduce_sum(tf.square(hypo-y_input))\n",
    "\n",
    "# Lancer l'apprentissage\n",
    "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "trainer = optimizer.minimize(cost)\n",
    "for it in range(iterations):\n",
    "    sess.run(trainer, {x: x_train, y: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
